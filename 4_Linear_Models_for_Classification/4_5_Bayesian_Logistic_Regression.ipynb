{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laplace appoximation\n",
    "\n",
    "## Prior distibution\n",
    "$$p(\\mathbf{w}) = \\mathcal{N}(\\mathbf{w}|\\mathbf{m}_0, \\mathbf{S}_0) \\tag{4.140}$$\n",
    "\n",
    "## Likelihood function\n",
    "$$p(\\mathbb{t}|\\mathbf{w}) = \\prod_{n=1}^N y_n^{t_n}\\{1-y_n\\}^{1-t_n} \\tag{4.89}$$\n",
    "\n",
    "where $y_n = \\sigma(a) = \\sigma(\\mathbf{w}^T\\phi)$\n",
    "\n",
    "## Posterior distribution\n",
    "$$p(\\mathbf{w}|\\mathbb{t})\\propto p(\\mathbf{w})p(\\mathbb{t}|\\mathbf{w}) \\tag{4.141}$$\n",
    "\n",
    "For the reason that the likelihood does not have the form of multiplication of Gaussian, the posterior is not Gaussian anymore. We therefore estimate the posterior distribution by finding its Gaussian approximation.\n",
    "\n",
    "$$q(\\mathbf{w}) = \\mathcal{N}(\\mathbf{w}|\\mathbf{w}_{MAP}, \\mathbf{S}_N) \\tag{4.144}$$\n",
    "\n",
    "where\n",
    "- the mean $\\mathbf{w}_{MAP}$ shall satisfy\n",
    "$$\\nabla\\ln p(\\mathbf{w}_{MAP}|\\mathbb{t}) = 0$$\n",
    "which can be evaluated using the <font color='red'>**IRLS**</font> approach introduced in Section 4.3.3, along with the following definition\n",
    "$$\\color{red}{\\nabla E(\\mathbf{w})}= \\nabla-\\ln p(\\mathbf{w}|\\mathbb{t}) = -\\nabla(\\ln p(\\mathbf{w})-\\nabla\\ln p(\\mathbb{t}|\\mathbf{w})\n",
    "\\color{red}{=(\\mathbf{w}-\\mathbf{m}_0)^T\\mathbf{S}_0^{-1}+\\sum_{n=1}^N(y_n-t_n)\\phi_n}$$\n",
    "$$\\color{red}{\\mathbf{H}} = \\nabla\\nabla E(\\mathbf{w}) = -\\nabla\\nabla\\ln p(\\mathbf{w}|\\mathbb{t}) \\color{red}{= \\mathbf{S}_0^{-1}+\\sum_{n=1}^Ny_n(1-y_n)\\phi_n\\phi_n^T} \\tag{4.143}$$\n",
    "- the inverse of the covariance $\\mathbf{S}_N$ is equal to the Hessian\n",
    "$$\\color{red}{\\mathbf{S}_N^{-1} = \\mathbf{H}}$$\n",
    "\n",
    "----------------\n",
    "\n",
    "# Predictive distribution\n",
    "If we input a new feature vector $\\phi(\\mathbf{x})$, then after replacing the posterior by the Laplace approximation, the probability of the new feature vector is given by\n",
    "\n",
    "$$p(C_1|\\phi, \\mathbb{t}) = \\int p(C_1|\\phi,\\mathbf{w})p(\\mathbf{w}|\\mathbb{t})d\\mathbf{w}\\simeq \\int \\sigma(\\mathbf{w}^T\\phi)q(\\mathbf{w})d\\mathbf{w} \\tag{4.145}$$\n",
    "\n",
    "Here we introduce the Dirac delta function $\\delta(\\cdot)$ and use its shift and sampling property\n",
    "\n",
    "$$\\begin{align*}\n",
    "p(C_1|\\phi,\\mathbb{t}) &= \\int \\sigma(\\mathbf{w}^T\\phi)q(\\mathbf{w})d\\mathbf{w} \\\\\n",
    "&=\\int \\left(\\int \\delta(a-\\mathbf{w}^T\\phi)\\sigma(a)da\\right)q(\\mathbf{w})d\\mathbf{w} \\tag{4.146}\\\\\n",
    "&=\\int \\sigma(a)\\left(\\int\\delta(a-\\mathbf{w}^T\\phi)q(\\mathbf{w})d\\mathbf{w}\\right)da \\tag{4.148}\\\\\n",
    "&=\\int \\sigma(a)p(a)da \\tag{4.147}\n",
    "\\end{align*}$$\n",
    "\n",
    "From (4.148), we can evaluate $p(a)$ by noting that the delta function imposes a linear constraint on $\\mathbf{w}$ and so forms a marginal distribution from the joint distribution $q(\\mathbf{w})$ by integrating out all directions orthogonal to $\\phi$.\n",
    "\n",
    "## Analyse $p(a)$\n",
    "Because $q(\\mathbf{w})$ is Gaussian, we know from Section 2.3.2 that the marginal distribution $p(a)$ will also be Gaussian.\n",
    "\n",
    "$$p(a) = \\mathcal{N}(a|\\mu_a,\\sigma_a^2)$$\n",
    "\n",
    "where the mean takes the form\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\color{red}{\\mu_a} = \\mathbb{E}[a] \n",
    "&= \\int p(a)ada \\\\\n",
    "&= \\int \\left(\\int\\delta(a-\\mathbf{w}^T\\phi)q(\\mathbf{w})d\\mathbf{w}\\right)ada\\\\\n",
    "&= \\int q(\\mathbf{w})\\left(\\int\\delta(a-\\mathbf{w}^T\\phi)ada\\right)d\\mathbf{w}\\\\\n",
    "&=\\int q(\\mathbf{w})\\mathbf{w}^T d\\mathbf{w}\\phi\\\\\n",
    "&=\\color{red}{\\mathbf{w}_{MAP}^T\\phi} \\tag{4.149}\n",
    "\\end{align*}$$\n",
    "\n",
    "The variance\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\color{red}{\\sigma_a^2} = var[a] \n",
    "&= \\int p(a)\\big\\{a^2-\\mathbb{E}[a]^2\\big\\}da \\\\\n",
    "&= \\int \\left(\\int\\delta(a-\\mathbf{w}^T\\phi)q(\\mathbf{w})d\\mathbf{w}\\right)\\big\\{a^2-\\mathbb{E}[a]^2\\big\\}da\\\\\n",
    "&= \\int q(\\mathbf{w})\\left(\\int\\delta(a-\\mathbf{w}^T\\phi)\\big\\{a^2-\\mathbb{E}[a]^2\\big\\}da\\right)d\\mathbf{w}\\\\\n",
    "&=\\int q(\\mathbf{w})\\big\\{(\\mathbf{w}^T\\phi)^2-(\\mathbf{w}_{MAP}^T\\phi)^2 \\big\\}d\\mathbf{w}\\\\\n",
    "&=\\int q(\\mathbf{w})\\big\\{(\\mathbf{w}^T\\phi)+(\\mathbf{w}_{MAP}^T\\phi)\\big\\}\\big\\{(\\mathbf{w}^T\\phi)-(\\mathbf{w}_{MAP}^T\\phi) \\big\\}d\\mathbf{w}\\\\\n",
    "&=\\int q(\\mathbf{w})\\phi^T\\big\\{\\mathbf{w}+\\mathbf{w}_{MAP}\\big\\}\\big\\{\\mathbf{w}^T-\\mathbf{w}_{MAP}^T\\big\\}\\phi d\\mathbf{w}\\\\\n",
    "&=\\phi^T\\int q(\\mathbf{w})\\big(\\mathbf{w}+\\mathbf{w}_{MAP}\\big)\\big(\\mathbf{w}-\\mathbf{w}_{MAP}\\big)^T d\\mathbf{w}\\phi\\\\\n",
    "&=\\phi^T\\left(\\int q(\\mathbf{w})\\big(\\mathbf{w}-\\mathbf{w}_{MAP}\\big)\\big(\\mathbf{w}-\\mathbf{w}_{MAP}\\big)^T d\\mathbf{w}+\\int q(\\mathbf{w})2\\mathbf{w}_{MAP}\\big(\\mathbf{w}-\\mathbf{w}_{MAP}\\big)^T d\\mathbf{w}\\right)\\phi\\\\\n",
    "&=\\phi^T\\Big(\\mathbb{E}\\big[(\\mathbf{w}-\\mathbb{E}[\\mathbf{w}])(\\mathbf{w}-\\mathbb{E}[\\mathbf{w}])^T\\big]-\\mathbb{E}\\big[\\mathbb{E}[\\mathbf{w}](\\mathbf{w}-\\mathbb{E}[\\mathbf{w}])\\big]\\Big)\\phi\\\\\n",
    "&=\\phi^T\\big(cov[\\mathbf{w}]-0\\big)\\phi\\\\\n",
    "&=\\color{red}{\\phi^T\\mathbf{S}_N\\phi} \\tag{4.150}\n",
    "\\end{align*}$$\n",
    "\n",
    "## Analyse $\\sigma(a)$\n",
    "The probit function (4.3.3) will have the same slope at the origin as the sigmoid function if we rescale the horizontal axis\n",
    "\n",
    "$$\\Phi(\\lambda a) \\simeq \\sigma(a)\\qquad where\\quad \\lambda^2=\\pi/8$$\n",
    "\n",
    "If we multiply the probit function by the Gaussian then take the result as integrand, it can be shown that\n",
    "\n",
    "$$\\int \\Phi(\\lambda a)\\mathcal{N}(a|,\\mu,\\sigma^2)da=\\Phi\\left(\\frac{\\mu}{(\\lambda^{-2}+\\sigma^2)^{1/2}}\\right) \\tag{4.152}$$\n",
    "\n",
    "We now apply the approximation $\\sigma(a)\\simeq \\Phi(\\lambda a)$ to the probit functions appearing on both sides of this equation, leading to the following approximation\n",
    "\n",
    "$$\\int\\sigma(a)\\mathcal{N}(a|\\mu,\\sigma^2)da\\simeq \\sigma(\\kappa(\\sigma^2)\\mu) \\tag{4.153}$$\n",
    "\n",
    "where we have defined\n",
    "\n",
    "<font color='red'>$$\\kappa(\\sigma^2) = (1+\\pi\\sigma^2/8)^{-1/2} \\tag{4.154}$$</font>\n",
    "\n",
    "\n",
    "Applying this result to (4.151) we obtain the approximate predictive distribution in the form\n",
    "\n",
    "<font color='red'>$$p(C_1|\\phi,\\mathbb{t}) = \\sigma(\\kappa(\\sigma_a^2)\\mu_a) \\tag{4.155}$$</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
