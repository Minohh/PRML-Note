{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM for regression\n",
    "\n",
    "The Lagrangian function of SVM regression problem is given by\n",
    "\n",
    "$$L(\\mathbf{a},\\mathbf{\\hat{a}}) = -\\frac{1}{2}\\sum_{n=1}^N\\sum_{m=1}^N (a_n - \\hat{a}_n)(a_m - \\hat{a}_m) k(\\mathbf{x}_n,\\mathbf{x}_m) - \\epsilon\\sum_{n=1}^N (a_n+\\hat{a}_n) + \\sum_{n=1}^N(a_n-\\hat{a}_n)t_n$$\n",
    "\n",
    "And our goal is to solve the following problem by making use of SMO.\n",
    "\n",
    "$$\\underset{0\\leqslant\\mathbf{a}\\leqslant C, 0\\leqslant\\mathbf{\\hat{a}}\\leqslant C}{\\quad max\\quad } L \\quad s.t.\\ \\sum_{n=1}^N (a_n - \\hat{a}_n) = 0 \\quad\\text{and}\\quad \n",
    "\\left\\{\\begin{array}{ll}\n",
    "\\text{if } a_n\\neq 0, &\\hat{a}_n = 0\\\\\n",
    "\\text{if } \\hat{a}_n\\neq 0, &a_n = 0\\\\\n",
    "\\end{array}\\right.$$\n",
    "\n",
    "Let $\\lambda_n = a_n - \\hat{a}_n$, by considering the constraint of these multipliers, we have $|\\lambda_n| = a_n + \\hat{a}_n$, and the range of $\\lambda_n$ is $[-C, C]$. We can then sustitute $\\lambda_n$ in to the Lagrangian function to obtain\n",
    "\n",
    "$$L = -\\frac{1}{2}\\sum_{n=1}^N\\sum_{m=1}^N \\lambda_n\\lambda_m k(\\mathbf{x}_n,\\mathbf{x}_m) - \\epsilon\\sum_{n=1}^N |\\lambda_n| + \\sum_{n=1}^N\\lambda_n t_n$$\n",
    "\n",
    "Now our goal becomes\n",
    "\n",
    "$$\\underset{-C\\leqslant\\mathbf{\\lambda}\\leqslant C}{max} L \\quad s.t.\\ \\sum_{n=1}^N \\lambda_n = 0$$\n",
    "\n",
    "which is equivalent to \n",
    "\n",
    "$$\\underset{-C\\leqslant\\mathbf{\\lambda}\\leqslant C}{min} \\Psi \\quad s.t.\\ \\sum_{n=1}^N \\lambda_n = 0\\qquad \\text{where}\\quad \\Psi = -L$$\n",
    "\n",
    "--------------------\n",
    "\n",
    "# KKT Conditions\n",
    "\n",
    "The KKT conditions are from Lagrange multipler and are significant for SVM and SMO. The KKT conditions for the QP problem are particularly simple. The QP problem is solved when, for all $i$:\n",
    "\n",
    "$$\n",
    "\\begin{array}{ll}\n",
    "a_n = 0\\text{ and }\\hat{a}_n=0 &\\Leftrightarrow &\\lambda_n = 0 &\\Leftrightarrow & |y_n - t_n|<\\epsilon \\\\\n",
    "0< (a_n \\text{ or } \\hat{a}_n)< C &\\Leftrightarrow& 0<|\\lambda_n|<C &\\Leftrightarrow & |y_n - t_n|=\\epsilon \\\\\n",
    "(a_n \\text{ or } \\hat{a}_n) = C &\\Leftrightarrow& |\\lambda_n|=C &\\Leftrightarrow & |y_n - t_n|>\\epsilon \n",
    "\\end{array}$$\n",
    "\n",
    "where\n",
    "\n",
    "- Points with $\\lambda_n = 0$ are inside the $\\epsilon$-tube.\n",
    "- Points with $0<|\\lambda_n|<C$ are at the boundary of the tube and support the tube.\n",
    "- Points with $|\\lambda_n| = C$ are outside the $\\epsilon$-tube.\n",
    "\n",
    "\n",
    "---------------\n",
    "\n",
    "# SMO\n",
    "\n",
    "Sequential Minimal Optimization (SMO) is a simple algorithm that can quickly solve the SVM QP (quadratic programming) problem without any extra matrix storage and without using numerical QP optimization steps at all. <font color='red'>SMO decomposes the overall QP problem into QP sub-problems</font>, using Osuna's theorem to ensure convergence.\n",
    "\n",
    "\n",
    "## Smallest SVM QP problem\n",
    "\n",
    "SMO chooses to solve the smallest possible optimization problem at every step. For the standard SVM QP problem, <font color='red'>the smallest possible optimization problem involves two parameters, because these parameters must obey a linear equality constraint.</font>\n",
    "\n",
    "$$\\sum_{n=1}^N \\lambda_n = 0 \\tag{2}$$\n",
    "\n",
    "It is nonsense to choose only one parameter for optimization, because if so, $a_n$ has to be fixed for suiting the linear equality constraint such that we cannot optimize the parameter $a_n$. Hence, at every step, SMO chooses two parameters to jointly optimize.\n",
    "\n",
    "$$\\lambda_1 + \\lambda_2 = - \\sum_{n\\neq 1,2}^N \\lambda_n=w \\tag{3}$$\n",
    "\n",
    "where the sumation of $\\lambda_1 + \\lambda_2$ is fixed. And the optimized parameters $\\lambda_1^{new}$ and $\\lambda_2^{new}$ has to be subject to the same constraint\n",
    "\n",
    "$$\\lambda_1^{new} + \\lambda_2^{new} = \\lambda_1 + \\lambda_2 = w \\tag{4}$$\n",
    "\n",
    "in order to keep meeting the linear equality constraint.\n",
    "\n",
    "\n",
    "## Ranges of $\\lambda_1$ and $\\lambda_2$\n",
    "\n",
    "There are two constriants on $a_1$ and $a_2$:\n",
    "\n",
    "$$\\begin{array}{ll}\n",
    "\\text{KKT requirement}&-C\\leqslant \\lambda_n \\leqslant C\\qquad \\text{where}\\quad n=1,\\cdots,N\\\\\n",
    "\\text{linear equality constraint} &\\lambda_1 + \\lambda_2 = w\n",
    "\\end{array} \\tag{5}$$\n",
    "\n",
    "The KKT condition requires the point $(\\lambda_2, \\lambda_1)$ to lie in the square with length $2C$. And the linear equality constraint requires the point $(\\lambda_2, \\lambda_1)$ lie on the line that is denoted by $\\lambda_1 + \\lambda_2 = w$.\n",
    "\n",
    "### Range of $\\lambda_2$\n",
    "\n",
    "$$\\left.\\begin{array}{ll}\n",
    "\\text{KKT requirement on }\\lambda_1 &-C\\leqslant \\lambda_1 \\leqslant C\\\\\n",
    "\\text{linear equality constraint} &\\lambda_2 = w - \\lambda_1\n",
    "\\end{array}\\right\\}\n",
    "\\Rightarrow \n",
    "\\lambda_2 \\in\n",
    "[w-C, w+C] \\tag{6}$$\n",
    "\n",
    "And $\\lambda_2$ must also be in the range $[-C, C]$, hence\n",
    "\n",
    "$$\\bbox[#e0f0ff]{a_2 \\in [L, H]\\qquad \\text{where}\\quad\n",
    "\\left\\{\\begin{array}{ll}\n",
    "L=max(w-C, -C) \\\\\n",
    "H=min(w+C, C)\n",
    "\\end{array}\\right.}\\tag{7}$$\n",
    "\n",
    "\n",
    "### Range of $\\lambda_1$\n",
    "\n",
    "We shall use the linear equation $\\lambda_1 + \\lambda_2 = w$ to evaluate the value of $\\lambda_1$. As long as $\\lambda_2\\in [L, H]$, the $\\lambda_1$ that derives from $\\lambda_2$ will also lie in the range of $[-C, C]$ and obey the linear equality constraint.\n",
    "\n",
    "\n",
    "*If $L\\geqslant H$, we cannot take the subsequent steps to optimize the pair of $\\lambda_1$ and $\\lambda_2$.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "REC_LINES = np.array([[-1, 1, 1, -1, -1], [-1, -1, 1, 1, -1]])\n",
    "SLANT_LINE_X = np.array([-2, 2])\n",
    "\n",
    "def hide_axes(ax):\n",
    "    ax.spines[\"top\"].set_color(\"none\")\n",
    "    ax.spines[\"bottom\"].set_color(\"none\")\n",
    "    ax.spines[\"left\"].set_color(\"none\")\n",
    "    ax.spines[\"right\"].set_color(\"none\")\n",
    "    ax.set_xlim(-1.2, 1.2)\n",
    "    ax.set_ylim(-1.2, 1.2)\n",
    "    \n",
    "def draw_rec(ax):\n",
    "    hide_axes(ax)\n",
    "    ax.plot(REC_LINES[0], REC_LINES[1])\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "def draw_line(ax, sign, k):\n",
    "    x = SLANT_LINE_X\n",
    "    y = k - sign*x\n",
    "    ax.plot(x, y)\n",
    "    \n",
    "def draw_range(ax, xstart, xend, y):\n",
    "    ax.annotate(\n",
    "        '', xy=(xstart, y), xycoords='data',\n",
    "        xytext=(xend, y), textcoords='data',\n",
    "        arrowprops={'arrowstyle': '<->', 'color':'r'})\n",
    "    ax.text(xstart+(xend-xstart-.5)/2, y-.2, r\"Range of $\\lambda_2$\", fontsize=14, color='r')\n",
    "\n",
    "def main():\n",
    "    fig=plt.figure(figsize=(12,5), dpi=50)\n",
    "    (ax1,ax2) = fig.subplots(1, 2)\n",
    "    draw_rec(ax1)\n",
    "    draw_rec(ax2)\n",
    "    \n",
    "    ax1.set_xticks([-1, 1])\n",
    "    ax1.set_yticks([-1, 1])\n",
    "    ax1.set_xticklabels([r\"$\\lambda_2 = -C$\", r\"$\\lambda_2 = C$\"], fontsize=15)\n",
    "    ax1.set_yticklabels([r\"$\\lambda_1 = -C$\", r\"$\\lambda_1 = C$\"], fontsize=15)\n",
    "    \n",
    "    K = np.array([-.5, .5])\n",
    "    S = np.array([-1, -1])\n",
    "    draw_line(ax1, S[0], K[0])\n",
    "    draw_line(ax2, S[1], K[1])\n",
    "    \n",
    "    i = 0\n",
    "    for ax in [ax1, ax2]:\n",
    "        xnc = S[i]*K[i] - S[i]*-1\n",
    "        xpc = S[i]*K[i] - S[i]*1\n",
    "        # print(x0, xc)\n",
    "        l = min(xnc, xpc)\n",
    "        h = max(xnc, xpc)\n",
    "        L = max(-1, l)\n",
    "        H = min(1, h)\n",
    "        draw_range(ax, L, H, -1.1)\n",
    "        i+=1\n",
    "    \n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Determine $a_2$\n",
    "\n",
    "Firstly, we shall extract the terms that related to $\\lambda_1$ and $\\lambda_2$ from the objective function.\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\Psi &= \\frac{1}{2}\\sum_{n=1}^N\\sum_{m=1}^N \\lambda_n\\lambda_m k(\\mathbf{x}_n,\\mathbf{x}_m) + \\epsilon\\sum_{n=1}^N |\\lambda_n| - \\sum_{n=1}^N\\lambda_n t_n\\\\\n",
    "&=\\underbrace{\\frac{1}{2}\\lambda_1 \\lambda_1 k_{11} + \\frac{1}{2}\\lambda_2 \\lambda_2 k_{22} + \\lambda_1 \\lambda_2 k_{12} + \\lambda_1\\sum_{n\\neq 1,2}^N \\lambda_n k_{1n} + \\lambda_2\\sum_{n\\neq 1,2}^N \\lambda_n k_{2n} + \\epsilon(|\\lambda_1| + |\\lambda_2|) - \\lambda_1t_1 - \\lambda_2 t_2}_{\\lambda_1,\\lambda_2 \\text{ related entries}\\qquad \\text{where }k_{ij}=k(\\mathbf{x}_i,\\mathbf{x}_j)} + constant\\\\\n",
    "&=\\underbrace{\\frac{1}{2}\\lambda_1^2 k_{11} + \\frac{1}{2}\\lambda_2^2 k_{22} + \\lambda_1 \\lambda_2 k_{12} + lambda_1 v_1 + \\lambda_2 v_2 + \\epsilon(|\\lambda_1| + |\\lambda_2|) - \\lambda_1t_1 - \\lambda_2 t_2}_{\\text{where } v_i=\\sum_{n\\neq 1,2}^N \\lambda_n k_{in}} + constant\\\\\n",
    "&=\\underbrace{\\frac{1}{2}(w-\\lambda_2)^2k_{11} + \\frac{1}{2}\\lambda_2^2k_{22} + (w-\\lambda_2)\\lambda_2k_{12} + (w-\\lambda_2) v_1 + \\lambda_2 v_2 + \\epsilon(|w-\\lambda_2|+|\\lambda_2|) - (w-\\lambda_2)t_1 - \\lambda_2 t_2}_{\\lambda_1+\\lambda_2 = w} + constant\\\\\n",
    "\\end{align*} \\tag{9}$$\n",
    "\n",
    "which is a quadratic function over $\\lambda_2$, and $\\lambda_1$ has been transfered to the form denoted by $\\lambda_2$ due to the constraint that <font color='red'>the sumation of $\\lambda_1$ and $\\lambda_2$ is fixed</font>.\n",
    "\n",
    "### First-order derivative\n",
    "\n",
    "We can take the first-order derivative of $\\Psi$ with respect to $\\lambda_2$ to obtain\n",
    "\n",
    "$$\\frac{d\\Psi}{d\\lambda_2} = -k_{11}(w-\\lambda_2) + k_{22}\\lambda_2 - k_{12}\\lambda_2 + k_{12}(w-\\lambda_2) - v_1 + v_2 + \\epsilon(-sgn(w-\\lambda_2)+sgn(\\lambda_2)) + t_1 - t_2 \\tag{11}$$\n",
    "\n",
    "\n",
    "However, this function is not continuous due to the $sgn$ function, we therefore have to deal with several segments of the function separately.\n",
    "\n",
    "### Second-order derivative\n",
    "\n",
    "The second-order derivative of $\\Psi$ with respect to $\\lambda_2$ is given by\n",
    "\n",
    "$$\\frac{d^2\\Psi}{d\\lambda_2^2} = k_{11} + k_{22} - k_{12} - k_{12} \\tag{12}$$\n",
    "\n",
    "Here we only consider the case that the kernel function satisfy the Mercer's conditions, which require the kernel $K$ is continuous and is given by\n",
    "\n",
    "$$k_{mn} = K(\\mathbf{x}_n, \\mathbf{x}_m) = \\phi(\\mathbf{x}_n)^T\\phi(\\mathbf{x}_m)$$\n",
    "\n",
    "With the Mercer's conditions, the second-order derivatives will always be positive provided $\\mathbf{x}_1$ not equal to $\\mathbf{x}_2$.\n",
    "\n",
    "$$\\begin{align*}\\eta = \\frac{d^2\\Psi}{d\\lambda_2^2} &= k_{11} + k_{22} - 2k_{12}\\\\\n",
    "&= \\phi(\\mathbf{x}_1)^T\\phi(\\mathbf{x}_1) + \\phi(\\mathbf{x}_2)^T\\phi(\\mathbf{x}_2) - 2\\phi(\\mathbf{x}_1)^T\\phi(\\mathbf{x}_2) \\\\\n",
    "&= \\big(\\phi(\\mathbf{x}_1) - \\phi(\\mathbf{x}_2)\\big)^2\\\\\n",
    "&>0\\qquad \\text{if }\\mathbf{x}_1\\neq \\mathbf{x}_2\n",
    "\\end{align*}$$\n",
    "\n",
    "Moreover, after adjustment, the first-order derivative with respect to $\\lambda_2$ takes the form \n",
    "\n",
    "$$\\frac{d\\Psi}{d\\lambda_2} = \\eta \\lambda_2 + \\epsilon(-sgn(w-\\lambda_2)+sgn(\\lambda_2)) + constant$$\n",
    "\n",
    "which is a discontinuous first-degree function of $\\lambda_2$ with a positive gradient, and can be depict as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "f = lambda x, eta, w, epsilon: eta*x + epsilon*(-np.sign(w-x) + np.sign(x)) + 1\n",
    "\n",
    "def draw_line(ax, eta, w, epsilon, L, H):\n",
    "    if w > 0:\n",
    "        s1 = 0\n",
    "        s2 = w\n",
    "        left_text = r'$\\lambda_1>0$, $\\lambda_2<0$'\n",
    "        mid_text = r'$\\lambda_1>0$, $\\lambda_2>0$'\n",
    "        right_text = r'$\\lambda_1<0$, $\\lambda_2<0$'\n",
    "        s1_text = r'$\\lambda_2 = 0$'\n",
    "        s2_text = r'$\\lambda_2 = w$'\n",
    "    elif w <= 0:\n",
    "        s1 = w\n",
    "        s2 = 0\n",
    "        left_text = r'$\\lambda_1>0$, $\\lambda_2<0$'\n",
    "        mid_text = r'$\\lambda_1<0$, $\\lambda_2<0$'\n",
    "        right_text = r'$\\lambda_1<0$, $\\lambda_2>0$'\n",
    "        s1_text = r'$\\lambda_2 = w$'\n",
    "        s2_text = r'$\\lambda_2 = 0$'\n",
    "    \n",
    "    x = np.linspace(-10, s1, 100)[:-1]\n",
    "    y = f(x, eta, w, epsilon)\n",
    "    ax.plot(x, y)\n",
    "    \n",
    "    x = s1\n",
    "    ys1 = f(x, eta, w, epsilon)\n",
    "    ax.scatter(x, ys1, s=20, color='C4')    \n",
    "    \n",
    "    x = np.linspace(s1, s2, 100)[1:-1]\n",
    "    y = f(x, eta, w, epsilon)\n",
    "    ax.plot(x, y)\n",
    "    \n",
    "    x = s2\n",
    "    ys2 = f(x, eta, w, epsilon)\n",
    "    ax.scatter(x, ys2, s=20, color='C5') \n",
    "    \n",
    "    x = np.linspace(s2, 10, 100)[1:]\n",
    "    y = f(x, eta, w, epsilon)\n",
    "    ax.plot(x, y)\n",
    "    \n",
    "    YL = f(L, eta, w, epsilon)-.5\n",
    "    draw_range(ax, L, s1, YL, left_text, 3, 'C0')\n",
    "    if w != 0:\n",
    "        draw_range(ax, s1, s2, YL, mid_text, 4, 'C1')\n",
    "    draw_range(ax, s2, H, YL, right_text, 3, 'C2')\n",
    "    if w != 0:\n",
    "        draw_arrow(ax, s1, ys2, ys1, s1_text, -.7, 'C4')\n",
    "        draw_arrow(ax, s2, ys1, ys2, s2_text, -.7, 'C5')\n",
    "    else:\n",
    "        draw_arrow(ax, s2, ys1+4, ys1-1, s2_text, -.7, 'C5')\n",
    "\n",
    "    \n",
    "def draw_range(ax, xstart, xend, y, text, adjust, color):\n",
    "    ax.annotate(\n",
    "        '', xy=(xstart, y), xycoords='data',\n",
    "        xytext=(xend, y), textcoords='data',\n",
    "        arrowprops={'arrowstyle': '<->', 'color':color})\n",
    "    ax.text(xstart+(xend-xstart-adjust)/2, y-1, text, fontsize=13, color=color)\n",
    "    \n",
    "def draw_arrow(ax, x, ystart, yend, text, adjust, color):\n",
    "    if ystart > yend:\n",
    "        delta_y = 1\n",
    "    else:\n",
    "        delta_y = -1\n",
    "    ax.annotate(\n",
    "        '', xy=(x, yend+1.5*delta_y), xycoords='data',\n",
    "        xytext=(x, ystart), textcoords='data',\n",
    "        arrowprops={'arrowstyle': '->', 'color':color})\n",
    "    ax.text(x+adjust, ystart+delta_y*.5, text, fontsize=13, color=color)\n",
    "\n",
    "def draw_pict(ax, w, C, eta, epsilon):\n",
    "    L = max(-C, w-C)\n",
    "    H = min(C, w+C)\n",
    "    \n",
    "    ax.set_xlim(L, H)\n",
    "    ax.set_ylim(f(L, eta, w, epsilon)-2, f(H, eta, w, epsilon)+1)\n",
    "    ax.set_xlabel(r\"$\\lambda_2$\", fontsize=14, color='grey')\n",
    "    ax.set_ylabel(r\"$\\frac{d\\Psi}{d\\lambda_2}$\", fontsize=18, color='grey')\n",
    "    \n",
    "    if w > 0:\n",
    "        s1 = 0\n",
    "        s2 = w\n",
    "        s1_text = r'$0$'\n",
    "        s2_text = r'$w$'\n",
    "    elif w < 0:\n",
    "        s1 = w\n",
    "        s2 = 0\n",
    "        s1_text = r'$w$'\n",
    "        s2_text = r'$0$'\n",
    "    else:\n",
    "        s1 = s2 = 0\n",
    "        s1_text = s2_text = r'$w=0$'\n",
    "    ax.set_xticks([L, s1, s2, H])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xticklabels([r\"$L$\", s1_text, s2_text, r\"$H$\"], fontsize=15)\n",
    "    \n",
    "    draw_line(ax, eta, w, epsilon, L, H)\n",
    "    \n",
    "def main():\n",
    "    fig=plt.figure(figsize=(21,4), dpi=50)\n",
    "    ax1, ax2, ax3 = fig.subplots(1, 3)\n",
    "    \n",
    "    eta = .3\n",
    "    epsilon = 1\n",
    "    C = 10\n",
    "    \n",
    "    ax1.set_title('w > 0')\n",
    "    w = 6\n",
    "    draw_pict(ax1, w, C, eta, epsilon)\n",
    "    \n",
    "    ax2.set_title('w < 0')\n",
    "    w = -6\n",
    "    draw_pict(ax2, w, C, eta, epsilon)\n",
    "    \n",
    "    ax3.set_title('w = 0')\n",
    "    w = 0\n",
    "    draw_pict(ax3, w, C, eta, epsilon)\n",
    "    \n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    " we can make use of the Newton method which is given by a closed form to obtain the optimum of $\\lambda_2$.\n",
    "\n",
    "$$\\lambda_2^{new} = \\lambda_2 - (\\frac{d^2 \\Psi}{d \\lambda_2^2})^{-1}\\frac{d\\Psi}{d\\lambda_2} \\tag{10}$$\n",
    "\n",
    "\n",
    "Note that only if the second derivative is possitive, which is the usual case, we can get the correct $\\lambda_2$, because we have assumed that this is a positive quadratic function and we are looking for the minimum of $\\lambda_2$.\n",
    "\n",
    "With these conditions, we can evaluate the new value of $\\lambda_2$ to minimize the objective function $\\Psi$.\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\lambda_2^{new} &= \\lambda_2 - \\frac{ -k_{11}(w-\\lambda_2) + k_{22}\\lambda_2 - k_{12}\\lambda_2 + k_{12}(w-\\lambda_2) - v_1 + v_2 + \\epsilon(-sgn(w-\\lambda_2)+sgn(\\lambda_2)) + t_1 - t_2 }{\\eta}\\qquad\\text{let }\\bbox[#e0f0ff]{\\eta=k_{11} + k_{22} - 2k_{12}}\\\\\n",
    "&= \\lambda_2 -\\frac{-k_{11}\\lambda_1 + k_{22}\\lambda_2 - k_{12}\\lambda_2 + k_{12}\\lambda_1 - v_1 + v_2 + \\epsilon(-sgn(\\lambda_1)+sgn(\\lambda_2)) + t_1 - t_2 }{\\eta}\\\\\n",
    "&= \\lambda_2 -\\frac{-\\big(k_{11}\\lambda_1 + k_{12}\\lambda_2 + v_1 - t_1\\big)+ \\big(k_{22}\\lambda_2 + k_{12}\\lambda_1 + v_2 -t_2\\big) + \\epsilon(-sgn(\\lambda_1)+sgn(\\lambda_2)) }{\\eta}\\\\\n",
    "&= \\lambda_2 -\\frac{-\\big(\\sum_{n=1}^N \\lambda_n k_{1n}-t_1\\big) + \\big(\\sum_{n=1}^N \\lambda_nk_{2n}-t_2\\big) + \\epsilon(-sgn(\\lambda_1)+sgn(\\lambda_2))}{\\eta}\\\\\n",
    "&= \\lambda_2 +\\frac{\\big(\\sum_{n=1}^N \\lambda_nk_{1n} + b - t_1\\big) - \\big(\\sum_{n=1}^N \\lambda_nk_{2n} + b - t_2\\big)- \\epsilon(-sgn(\\lambda_1)+sgn(\\lambda_2))}{\\eta}\\\\\n",
    "&= \\lambda_2 +\\frac{\\big(y_1 - t_1\\big) - \\big(y_2 - t_2\\big)+ \\epsilon(sgn(\\lambda_1)-sgn(\\lambda_2))}{\\eta}\\\\\n",
    "&= \\bbox[#e0f0ff]{\\lambda_2 + \\frac{E_1-E_2+ \\epsilon(sgn(\\lambda_1)-sgn(\\lambda_2))}{\\eta}\\qquad \\text{let } E_1 = y_1-t_1\\quad E_2 = y_2-t_2} \\tag{13}\n",
    "\\end{align*} $$\n",
    "\n",
    "The obtained $\\lambda_2$ is then clipped by the constraints $L$ and $H$.\n",
    "\n",
    "$$\\bbox[#e0f0ff]{\n",
    "\\lambda_2^{new} = \\left\\{\\begin{array}{ll}\n",
    "H &if &\\lambda_2^{new} \\geqslant H\\\\\n",
    "\\lambda_2^{new} &if & L<\\lambda_2^{new}<H\\\\\n",
    "L &if &\\lambda_2^{new} \\leqslant L\n",
    "\\end{array}\\right.} \\tag{14}$$\n",
    "\n",
    "\n",
    "\n",
    "### Non-positive second-order derivative\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Determine $a_1$\n",
    "\n",
    "With $\\lambda_2^{new}$, we can derive the new value of $\\lambda_1$ from the constraint\n",
    "\n",
    "$$\\bbox[#e0f0ff]{\\lambda_1^{new} = \\lambda_1 + \\lambda_2-\\lambda_2^{new}} \\tag{18}$$\n",
    "\n",
    "\n",
    "## Output function update\n",
    "\n",
    "From the updating equation of $a_2$, we notice that each update of $a_2$ needs the outputs $y_1$ and $y_2$. The output function is given by\n",
    "\n",
    "$$y(\\mathbf{x}) = \\sum_{n=1}^N \\lambda_n k(\\mathbf{x},\\mathbf{x}_n) + b \\tag{19}$$\n",
    "\n",
    "where $a_1$ and $a_2$ have updated, and the remaining term is the threshold $b$. The threshold $b$ is given by\n",
    "\n",
    "$$b = \\frac{1}{N_{\\mathcal{M}}}\\sum_{n\\in\\mathcal{M}}\\left(t_n - \\sum_{m\\in\\mathcal{S}}\\lambda_m k(\\mathbf{x}_n, \\mathbf{x}_m)\\right) \\tag{20}$$\n",
    "\n",
    "where $\\mathcal{M}$ denote the set of the indices of which parameters satisfy $0<|\\lambda_n|<C$, and $\\mathcal{S}$ denote the set of the indices of which parameters satisfy $|\\lambda_m|>0$. We can use this equation to compute the initial $b$. However, for each update of $b$, its worst computational complexity is $O(N^2)$. \n",
    "\n",
    "Here we shall introduce a simple and efficient method to update $b$. This method derives from the KKT conditions. \n",
    "\n",
    "$$0<|\\lambda_n|<C \\Leftrightarrow |y_n - t_n| = \\epsilon \\tag{21}$$\n",
    "\n",
    "Recall that $\\lambda_n = a_n - \\hat{a}_n$, where $a_n$ and $\\hat{a}_n$ subject to the constrinat $\\left\\{\\begin{array}{ll}\n",
    "\\text{if } a_n\\neq 0, &\\hat{a}_n = 0\\\\\n",
    "\\text{if } \\hat{a}_n\\neq 0, &a_n = 0\\\\\n",
    "\\end{array}\\right.$. As a result, we can eliminate the absolute operation to obtain\n",
    "\n",
    "$$\\begin{array}{ll}\n",
    "\\text{if }0<\\lambda_i <C , & E_i = y_i - t_i = -\\epsilon\\\\\n",
    "\\text{if }-C<\\lambda_i<0 , & E_i = y_i - t_i = \\epsilon\n",
    "\\end{array}$$\n",
    "\n",
    "which implies that when $\\lambda_i$ or $\\lambda_2$ is not at the bounds, the QP sub-problem over $\\lambda_1$ and $\\lambda_2$ can be solved by forcing $y_1$ or $y_2$ to satisfing $|y_i - t_i| = \\epsilon$, which can be achived by modifying $b$.\n",
    "\n",
    "When $0<\\lambda_i <C$,\n",
    "\n",
    "$$\\begin{align*}\n",
    "-\\epsilon = E_i^{new} &= E_i + \\Delta E_i\\\\\n",
    "&= E_i + \\Big(\\Delta \\lambda_1 k(\\mathbf{x}_i, \\mathbf{x}_1) + \\Delta \\lambda_2 k(\\mathbf{x}_i, \\mathbf{x}_2) + \\Delta b\\Big) \\tag{22}\\\\\n",
    "-\\Delta b &= E_i + \\Delta \\lambda_1 k(\\mathbf{x}_i, \\mathbf{x}_1) + \\Delta \\lambda_2 k(\\mathbf{x}_i, \\mathbf{x}_2) +\\epsilon \\tag{23}\n",
    "\\end{align*}$$\n",
    "\n",
    "When $-C<\\lambda_i <0$,\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\epsilon = E_i^{new} &= E_i + \\Delta E_i\\\\\n",
    "&= E_i + \\Big(\\Delta \\lambda_1 k(\\mathbf{x}_i, \\mathbf{x}_1) + \\Delta \\lambda_2 k(\\mathbf{x}_i, \\mathbf{x}_2) + \\Delta b\\Big) \\tag{22}\\\\\n",
    "-\\Delta b &= E_i + \\Delta \\lambda_1 k(\\mathbf{x}_i, \\mathbf{x}_1) + \\Delta \\lambda_2 k(\\mathbf{x}_i, \\mathbf{x}_2) - \\epsilon \\tag{23}\n",
    "\\end{align*}$$\n",
    "\n",
    "Then we can obtain the new threshold $b^{new}$ \n",
    "\n",
    "$$\\bbox[#e0f0ff]{\n",
    "b^{new} = \\left\\{\\begin{array}{ll}\n",
    "- E_i -  (\\lambda_1^{new} - \\lambda_1) k(\\mathbf{x}_i, \\mathbf{x}_1) - (\\lambda_2^{new} -\\lambda_2) k(\\mathbf{x}_i, \\mathbf{x}_2) - \\epsilon + b & \\text{if }0<\\lambda_i <C\\\\\n",
    "- E_i -  (\\lambda_1^{new} - \\lambda_1) k(\\mathbf{x}_i, \\mathbf{x}_1) - (\\lambda_2^{new} -\\lambda_2) k(\\mathbf{x}_i, \\mathbf{x}_2) + \\epsilon + b & \\text{if }-C<\\lambda_i <0\n",
    "\\end{array}\\right.}$$\n",
    "\n",
    "\n",
    "We shall obtain two thresholds, $b_1^{new}$ for $\\lambda_1^{new}$ and $b_2^{new}$ for $\\lambda_2^{new}$. \n",
    "- When the new parameters $\\lambda_1^{new}$ and $\\lambda_2^{new}$ are both not at the bounds, these two thresholds are equal, and the new thresholds is set to be $b^{new} = b_1^{new} = b_2^{new}$.\n",
    "- When there is only one parameter not at the bound, SMO chooses the threshold of which parameter not at the bound.\n",
    "- When two parameters are both at the bound, SMO chooses the threshold to be halfway between $b_1^{new}$ and $b_2^{new}$.\n",
    "\n",
    "\n",
    "## How to pick $\\lambda_1$ and $\\lambda_2$\n",
    "\n",
    "In the previous part we mainly focus on how to evaluate the value of $\\lambda_2$, however, the effects on $\\lambda_1$ and on $\\lambda_2$ are analogous, because this process is looking for the optimum of $\\lambda_1$ and $\\lambda_2$ that lie in the region of $[-C, C]$ and obey the linear equality constraints as well as minimize the objective function. Note that this is a local optimum, because the linear equality constraint depends on $\\lambda_1 + \\lambda_2 = w$, where $w$ will change along the SMO progresses and be stable finally.\n",
    "\n",
    "As a result, we may need multiple loops of optimizations to obtain the final result.\n",
    "\n",
    "### Pick the first parameter\n",
    "\n",
    "The outer loop picks $\\lambda$ following the rules below.\n",
    "\n",
    "1. In the first loop, we shall pick every $\\lambda_n$ as the first parameter because they are just initialized.\n",
    "2. In the subsequent loops, we shall pick the non-bound $\\lambda_n$ as the first parameter because these examples are most likely to violate the KKT conditions. We keep running this step until all the non-bound $\\lambda_n$ obey the KKT conditions.\n",
    "3. In the last loop, we shall pick every $\\lambda_n$ as the first parameter for KKT condition validation. If the validation fails, step 2 is invoked again.\n",
    "\n",
    "And before going into the inner loop to pick the second parameter, we shall check if the picked first parameter violate the KKT conditions. If not, we should discard the parameter and continue to the next iteration. <font color='red'>In a word, the first picked parameter has to be KKT conditions violated, because the Osuna's theorem suggests that only if at least one of the parameter violated the KKT conditions the optimization process can decrease the objective function.</font>\n",
    "\n",
    "### Pick the second parameter\n",
    "\n",
    "The goal of the inner loop is to pick one parameter from the array of parameters. Now suppose that the index of the first parameter is given by $i$ and $j$ denote the index of the second parameter that will be selected. The order of selection should follow the rules as follows.\n",
    "\n",
    "1. SMO firstly select the parameter on the index $j$, where $j$ gives the biggest $|E_1 - E_2|$, namely $|E_i - E_j|$. Because SMO want to maximize the size of step taken during joint optimization. From equation (13), we know that the step size is given by $\\frac{|E_1 - E_2|}{\\eta}$, however, evaluating the kernel function is time consuming, so SMO approximates the step size by the absolute value of the numerator in the equation.\n",
    "2. If the above heuristic dose not make positive progress, then SMO starts iterating through the non-bound parameters.\n",
    "3. If non of the non-bound examples make positive progress, then SMO starts iterating through the remaining parameters.\n",
    "\n",
    "\n",
    "------------\n",
    "\n",
    "# Overall procedure\n",
    "\n",
    "1. Initialization.\n",
    "  - The parameters should be in the range $[-C, C]$ and satisfy the linear equality constraints.\n",
    "  - Using the initialized parameters to compute the errors.\n",
    "2. The outer loop is to pick the first parameter that violate the KKT conditions. The rules of iterations is as follows:\n",
    "  - If this is a initial loop or a validation loop, iterate all the parameters.\n",
    "  - Otherwise, iterate the non-bound parameters.\n",
    "3. The inner loop is to pick the second parameter and then optimize these two picked parameters. The precedence is as follows.\n",
    "  - The error of the chosen example should give the biggest difference from the error of the example of the first parameter.\n",
    "  - Iterate the non-bound parameters.\n",
    "  - Iterate the remaining parameters.\n",
    "4. Optimize the two chosen parameters.\n",
    "  - Compute the range $[L, H]$ for $\\lambda_2$.\n",
    "  - If $L$ is equal to $H$, then current optimization fails.\n",
    "  - Compute the second-order derivative with respect to $\\lambda_2$.\n",
    "  - Evaluate the new $\\lambda_2^{new}$ with Newton method.\n",
    "  - If $\\lambda_2^{new}$ is equal to $\\lambda_2$, then current optimization fails.\n",
    "  - Compute the new threshold $b^{new}$.\n",
    "  - Compute the new error for the next optimization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-e9fe8d118f7a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    374\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 375\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-36-e9fe8d118f7a>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    367\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m     \u001b[0msmo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSMO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 369\u001b[1;33m     \u001b[0msmo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    370\u001b[0m     \u001b[0msmo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-36-e9fe8d118f7a>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    283\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mis_kkt\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m                                 \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 285\u001b[1;33m                                 \u001b[0mupdate\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpair_optimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    286\u001b[0m                     \u001b[1;31m# if update == 0, means the parameter a could already be the best, then update the threshold b\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mupdate\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-36-e9fe8d118f7a>\u001b[0m in \u001b[0;36mpair_optimize\u001b[1;34m(self, i)\u001b[0m\n\u001b[0;32m    235\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpair_optimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m         \u001b[0mlength\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 237\u001b[1;33m         \u001b[0mj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    238\u001b[0m         \u001b[0mupdate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mupdate\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\OtherProgram\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36margmax\u001b[1;34m(a, axis, out)\u001b[0m\n\u001b[0;32m   1101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m     \"\"\"\n\u001b[1;32m-> 1103\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'argmax'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\OtherProgram\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;31m# An AttributeError occurs if the object does not have\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAn4AAADdCAYAAAAlx38JAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAJOgAACToB8GSSSgAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xl81dWd//HXSchOIAshSNgJYVcQiLiACyCLC9ZfwbWdim0dpx1t69JOO3VrK7UyM7UzU+10BsfWpYK7VnAdqQsQxA1FCZuIkISQjezbPb8/zr1wiQGy3Htz7837+XjwgLt9z7mE++F9z/d8zzHWWkREREQk+sX0dAdEREREJDQU/ERERER6CQU/ERERkV5CwU9ERESkl1DwExEREeklFPx6CWNMTZvb3zLG/EeAjn2HMebmQBzrBO28YYyZ3onnzzTGbDTGfGCM+dTbzxHGmC+NMTFtnvuBMSbf+5x93ttbjTFXBP6diEi0McZ8bowZ0M79Ne09P4j9SDbGPGKM2WKM+dgY85Yxpq+3fs5v89wfGGN+762L9X5170/GmLhQ9ltCR8FPotlDwHettVOAScAqa+3nwF5glu9JxphxQKq1tsB71795X7MY+IMKoIj0NGNMbAefeiNQYq2dbK2dBFwLNAOPAZe3ee7l3vsBdnrr3mRgCLC0+72WcKTgJxhjLvKOjL1vjHnVGJPtvf8OY8xK7zfFXcaYG/xe8zNjzDZjzKvA2GMcd4Qx5jNjzH97v3k+YoyZa4x52xiz3RiT731evjHmHW/77xhjxnrvTzLG/MUY85Ex5nEgye/Y5xtj1htj3jPGrDbG9G2nCwOBIgBrbau1dqv3/rYF0L/4HWat3Q7UAekd/bsUkehmjEkxxvzVGPOht65d1ubxJGPMWmPMd9p57S3GmE3emnan3/3PGGM2G2M+McZ81+/+GmPMXcaYjcDp3lHFO711b4v3S2tbJwH7fDestdustY3AE8CFxpgE77FHAIOBt/xfbK1tBQqAnE7/5UhEUPDrPZK8w/gfGGM+AO7ye+wtYKa1dirwF+BWv8fGAfOBfOB2Y0ycMWYaLixNBS4FZhyn3VzgPuBk77GuBM4CbgZ+6n3OZ8Bsb/u3AXd7778eqLPWngz8CpgG4D2d8s/AXGvtqcC7wI/aafvfgG3GmKeNMdcZYxK9968CLjHG9PHevsz7vo9ijDkV2G6tPXCc9ycivcsCYL+19hTviNpav8f6As8Dj1pr/+j/ImPM+cAYXC2dAkwzxsz2PrzMWjsNmA7cYIzJ9N6fAnxsrT3NWusLaAe9de9+XB1tayXwY+8X418aY8YAWGvLcIFugfd5lwOP2za7OHjr5Glt3pdEEQW/3qPeWjvF9wsXsHyGAC8ZY7YAtwAT/R77q7W20Vp7EDgAZONOkz5tra2z1h4CnjtOu7uttVustR7gE+A1b6HZAozwPqc/sNoY8zEurPnanw08DGCt/Qj4yHv/TGAC8LY3xP4dMLxtw9bau3CF9GVc4Fzrvb/Y25c5xpgpQLO19mO/l/7QGLMN2AjccZz3JiK9zxZgrjHmHmPMLGttld9jzwIPWmv/1M7rzvf+eh94D/dFeIz3sRuMMR8CG4Chfve3Ak+2Oc5T3t83c6SGHmat/QAYBdwLZACbjDHjvQ/7n+1oe6ZjtLeelgFfeGuuRCEFPwH4d+A/rLWTgeuARL/HGv3+3Ar4Rsm+stefMWao36ji37fzeo/fbY/fsX4B/J/32/NFbdpvb09BA7ziF2QnWGuvbe+NWWt3WmvvB+YAp/h9k/YVwPZO8/6btXYsbiTwT34jhSLSy1lrC3FnH7YAy40x/l+i3wYWGmNMOy81wHK/upVrrf0fY8w5wFzgdGvtKbhg6Ks5Dd5Tr/58NdS/HrftY4219ilr7T/gvjwv8j70DO4L76lAkrX2Pb+X+eb45QIzjTEXn+jvQiKTgp+AG3HzzQn5uw48/2/A17xzWVJxYQ1r7V6/ovZAF9v/Vpt2rgIwxkzCnS4G9634TGNMrvexZGNMXtuDGmMu8CvAY3CFstJ7+0lcMWz3NK/3/TyFO43ckb8TEekFjDGDcVNQHgZWAKf6PXwbbsTs9+289CVgmW8+sjEmxxgzEFf/Kqy1dd45ezO72b8zjTHp3j/H486O7AEXCIE3cKeDvzKv2fucIuAnwD91px8SvhT8BNzpzNXGmDeBgyd6svdb4uPAB7gA9WY32/8N7pvz24D/lWv3A32NMR/h5h0WeNsvxQXEx7yPbcCdNmnrG7g5fh8Afwau8n17ttZWel9XYq3dfZy+3QX8yLRZ/kVEeq3JQIG3rvwM+GWbx38AJBpjfuN/p7X2ZeBRYL13Ws0TQCpuCkofby37Ba4udcdoYJ23jfdxX179Txc/BpzCMb7wej0DJBtjZh3nORKhTJt5nSIiIiISpbo8imGMmeRdlmOd99L29pbTEBHplVQjRSQcdXnEzxgTZ61t9v75dmCXtfbPgeyciEikUo0UkXDU5RE/X0HzSsatxSYiIqhGikh46taEdWPMPGPM+8C5wM7AdElEJDqoRopIuAnIxR3GmFuBGGvtr723lwBLAEaOHLlk+vTp3W5DRHq31atXv+fd3SDitK2R3vtUJ0UkoDpSJ9td/LEjjDEJ3v3/AKqAeN9j1trVwGqApUuX2lWrVnW1GRERAIwxETVidrwaCaqTIhJ4HamTXQ5+wDxjzC24HRh866qJiIijGikiYafLwc9a+wLwQgD7IiISNVQjRSQcaTcCERERkV5CwU9ERESkl1DwExEREeklFPxEREREegkFPxEREZFeQsFPREREpJdQ8BMRERHpJRT8RERERHqJ7uzcISIiIiI9rbYWPvqIVEg60VMV/EREREQiUW0tvP8+fPYZ1NeTAHEneomCn4iIiEgkqamB996DwkKIj4fsbCgr69BLFfxEREREIkF19ZHAl5joAl8nKfiJiIiIhLNDh2DzZtixA5KSYNCgLh9KwU9EREQkHFVVwbvvwq5dkJzcrcDno+AnIiIiEk4qK2HTJvj884AFPh8FPxEREZFwUFHhAt+ePZCSEtDA56PgJyIiItKTysuhoAD27oW+fYMS+HwU/ERERER6QlkZbNwI+/YFPfD5KPiJiIiIhNLBgy7w7d8PqakhCXw+Cn4iIiIioVBaChs2QHEx9OsX0sDno+AnIiIiEkwHDrjAV1LSY4HPR8FPREREJBhKSmD9ejfS18OBz0fBT0RERCSQiorcCF9ZWWgCX0stVL7Soad2OfgZY6YBvwU8QAlwlbW2uavHExGJJqqRIr2MtS7wrV/v1uPr379Le+l2SksNHFgLJS+BSejQS7oz4rcPmG+trTPG3A1cAqzuxvFERKKJaqRIb2Ctuzp3/Xq340ZaWggCXzWUrIEDL0OfVBhyJZgJwHdO+NIuBz9rbbHfzWagpavHEhGJNqqRIlHOWrf+ni/wpacHP/A1V7nAV/oKxPWHod+AzDPB9HGnlTug23P8jDHDgLnAL/3uWwIsAZg5c2Z3mxARiVjt1Ujv/aqTIpHIWrfDxoYNUFXlAl+w5/A1V0LJi1D6GsSlw7BvQcYZYGI7fahuBT9jTD/gz8A1/nNXrLWr8Z7SWLp0qe1OGyIikepYNRJUJ0UijsfjAt/69VBdDRkZwQ98TRVQ8gKUvg4JWTD8WkifCSamy4fszsUdscAjwF3W2sIu90BEJAqpRopECY8HvvjCjfDV1IRmhK+pDIpfgINvQEI2jLgO0vO7Ffh8ujPitxQ4A0g1xvwcuN9a+3i3eyQiEh1UI0UimccDe/a4wFdb60b4gj2Hr+kgFD0PZesgcTCMvB7Spgck8Pl05+KOx4DHAtYTEYkIBQVw881QWAh5ebBiBeTn93Svwo9qpEiE8nhg924X+OrrXeDr27dThygshJUrYd9+yBkMy5a5enlMjQeg+Hko+xskDoFR34f+pwY08PloAWcR6bCCAliwwC1RBW5R+gULYO1ahT8RiXCtrbBrF2zcCA0NLvD169fpwxQWwu23Q02tu11Z6W7feWc74a+xBIqeg7K3IHkYjLoR+k8FY7r/fo5BwU9EOuzmm4+EPp+KCrjlFli3rmf6JCLSLa2tsHOnC3yNjZCZ6RZf7qKVK4+EPp+aWnjwQVi+3HtHQxEUPQvl70DKSMj9EfQ7OaiBz0fBT0Q6rPAYlyhs2xbafoiIdFtLC+zYAZs2QVOTG+FLS+v2Yfftb//+L/cB9fug+FkoXw8puTDmFkidFJLA56PgJyIdlpfnTu+2NXZs6PsiItIlLS3uW+ymTe7PmZkQ2/n18I4lZ7A7vetvWNZevnvRs7B1I/QdC2N+AqkTQhr4fBT8RKTDVqw4eo4fuJUN7r235/okItIhzc2wfbsLfK2tboQvgIHPZ9myI3P8Rgz8gstmP8NZEwuoi50Ao38KqeMD3mZnKPiJSIfl57sLOW65xZ3eHTvWhT5d2CEiYau5GT77DDZvdlfsBinw+eTlwa9v+5ya7U8zMWcz20sm8UXSzxk2ITxOjSj4iUin5OfrQg4RiQBNTUcCn7VBD3wA1O6EomcYXvc+jD8FTrqdMdPGBLfNTlLwExERkbDS4mmhsaWR5LhkTGfnwTU1waefwnvvudsZGRAT+PXwjlKzA4qehkMfuuVYxt0JKaOD26Y/jwfq67Fwwu0fFfxERESkxzW2NLJ662oeePcBKhsqSYpLorKhkoW5C7l++vWMzzrB3LjGRti6FT74wF00EZLAV+gNfFug/zQY/wtIHhncNv21tkJ5uXu/Z55JBdSc6CUKfiIiItKjSmtLufgvF3P6kNN56JKHGJ3hRsuaW5t5dtuzfOPpb/CdU7/DddOv++qLGxvhk09CG/iqP4Oip6B6K6TNgPG/guThwW3Tny/wxcTAjBkwbhzExeHRiJ+IiIiEs8aWRhb/ZTG3nnErXxv/taMei4uN4+sTvs7C3IVc9NhFZCRlsGTiEvdgQwN8/DF8+KGbu5eZGdzAZ60LekVPQ802SM+HCcshaWjw2mzLF/hiY92E67FjIS6uU4dQ8BMJMe11KyJyxBNbn+C0nNMOh772a2QKj3/9cc596Fz+38hFxHz8CWzZAn36QFZWcNfDsxaqP/YGvu2QcTpM+DUk5QSvzbb8A9/Mme4vpk/XIpyCn0gIaa9bEZGjPbD5AR5c/CBwgho5uS/T44bz8sqfsSB1amgC36GPXOCr3QkZZ8LEb0Pi4OC12VZLiwt8cXFw+ukwZkyXA5+Pgp9ICGmvWxGRI1o9rZTXl5ObkQu0XyMbKup48LqPyP/ex1zYPJI3++xjQcac4HXKWqj6wAW+us8h8ywY8feQOCh4bbblC3zx8XDWWZCbG7ClaBT8REJIe92KiBzR1NpEQmzC4dv+NTKZWk7mQyayldhd8TBwIMmHMmms3heczlgLVZth/9NQ/yUMmAWjvg8JA4PTXntaWqCsDBITYdYsGD064GsPKviJhJD2uhUROSKxTyLVTdU0tTYRHxtPXh7UlNRwCh8wjs9oJIESBjJpqAEDhY37yInLDGwnrAcq34WiZ6BhH2SeDaN/CAkDAtvO8TQ3uxG+xEQ45xwYOTJoi00r+ImEkPa6FRE5whjDBWMu4KlPn+Ly4RfwwJXv88C7hVTUx3OAbAD6psA114C1lv8te521uXcEpnHrgYoCF/gai2HAuZB7E8QHOFgeT3Oz+w8hKQnOPdcFviAvRaPgJxJC2utWRORo14/7Blc8eQUXph5kQkp/vv+LbB58ENgHQ3Jc6MvLg0fK1zEhcSiD4tK716D1QMUGb+ArhaxzIftWiM8IyPvpEN8IX0oKnHceDB8e/LUHvRT8REJMe92KiACHDsHmzYzdsYPvJc3mwuo/8PiAW8jLg+XLjzzNWssj5ev415JneXXML7renm2F8vUu8DWVQ9YcGLQIuhskO6OpyY3w9e0Lc+fCsGEhC3w+Cn4iIiIhsrtiN9vK3NVc4weMZ3haCHd7CBdVVfDuu7BrFyQnw6BBXMti0iuymLv9NqYkj+Si/vkkmXh2NBbxUPnrTEocxqtjfkF6n76db8+2QNnbUPwsNFdB1lzIXgRx/QP/3o7FF/j69YN582Do0JAHPh8FPxERkSB7bddr/Oad31DbVMuMwTOwWO5adxfpSencesatnD3i7J7uYvBVVsKmTfD554cDn79L08/gkrSZvFb9IX+r+YRGTzOD4zNYm3tH107velqg/E0oeg5aqmHgPBi4EOL6BeTtdEhjowt8/fu7Cd45OcFde7ADFPxERESC6D8L/pNVW1dx34L7mDJoylGPbd6/mRvW3sCyKcu49tRre6iHQVZR4QLfnj1uTtugY6+HF2NimNdvKvP6Te16e55mKPsbFD8HLXUw8HzIXgB9Urt+zM7yBb60NFi4MCwCn0+Xg58xJhV4FZgIzLTWfhywXomIRAHVSXll5yus2rqKl65+icQ+iV95fNrgabx89cuc//D5jMkcw+zhs3ugl0FSXu624ti7181pO07gCwhPExxcB8XPg6cBBi6AgfOhT0pw2/XX0OBOZaenwwUXwEknhU3g8+nOCeZ64ELgiQD1RSJcQQHMnu0+27Nnu9sivZzqZC/3m3d+w38s/I/Doa+9OpkSn8Jv5/+WFe+s6OHeBkhZGbz4Ijz5pBv1GjTIBb9g8TTBgZfg45tg/xOQdR5M/i0MvjR0oa+hAYqL3XZqF1wAl14KgweHXeiDboz4WWtbgFIThm9KQk970Ip8lepk77azfCeNLY1Mzp4MnKhOzqCktoQvD33JkH5DerDX3XDwIGzcCPv3Q2pqCEb4GqH0NSj+q7tid9Aid+FGbHJw2/VXX+9G+LKy4KKLgv+eAyAoc/yMMUuAJQAzZ84MRhMSZrQHrUjnqE5Gv08PfsppOacdvn2iOpk/OJ9tB7dFXvArLYUNG9yIV79+wQ8/rQ1Q+iqUvOhuZ/sC31dPpQdNXZ1bjmbgQFi82P0eIYIS/Ky1q4HVAEuXLrXBaEPCi/agFekc1cneJ+rq5IEDsH69+z0kga8eSl+BkjVADAy6EAac1zOBb9Agt/ByVlbo2g4QXdUrAaE9aEVEjjZ+wHh+8/ZvDt8+UZ0s2F/Aj8/6cYh61w0lJS7wlZa6ZUqCHvjq4MDLULIWYuLgpEvc9mox8cFt119tLVRXu3l7c+bAgBDu4xtg3Qp+xpgXgSnAWGPMH6y1/xuQXknE0R60Iu1Tney9RmeMJqFPAltKtjA5e/Jx6+SmfZvITskO39O81rpTuRs2uLl8oQh8LbXuoo0DayEmEQb/PxhwdmgDX02N+5WT4xZezgzhPr5B0q3gZ61dFKiOSGTTHrQi7VOd7N1uPeNWvr/m+6y9ai35+Unt1smJU2o5/+EfsHzO8hMfMNSshaIiN8LnW4g46IGv2o3uHXgZ+iRDzmWQOduN9oWKL/ANHQrz50NGCPfxDTKd6pWA0R60IiJHmzd6HoVlhSx4ZAH3LbiP/PwpR9XJzfs3c/7DbgHnsFrDz1p3da4v8KWnQ3Z2cNtsqXYXbBx4xS22PPRKyJgFMYGLKnubSvmvgy/xdOUGWq0HD5YpSSP5h6xFzO47EVNT407rDh8edYHPR8FPREQkiL6X/z3GDhjLT179CTVNNYe3bNu4byOZSZncfd7d4bNlm7Wwbx+8886RhYiDPcLXXOUCX+mrbv/cod+EzDPABDaiPFT2GitKnuGGgReycewKUmITsdbyZs0n3Lf/ae5rXc0jp9xF0qJFbseNKKXgJyIiEmRzR81l7qi57K7YTWGZu7z3hzN/yPC04T3cMy9r3Q4bGza4q1bT0kIQ+CrdGnylr0F8Bgy7BjJOBxMb8KaeqHibB8te452x95Dqt86fqa5mdt0AZk9dzr+Y9VxVupIn+19ANK+8qeAnEmUKCtx6YYWF7irCFSs011IkXIxMH8nI9JE93Y0jPB744gsX+GpqQnNKt6kCSp6H0v+DhCwY8W1InwmmO5uJHVuLbeW2okd5M2/54dC3870qnny4ng0Hc6kbP427ftuPm/LnsGH1Et74/A3OHXluUPoSDhT8RKKIdlARkQ7xBb71692ctoyMEAS+Mih+AQ6+AQnZMOI6SM8PWuDz+WvVJmb3nUhmn35QWcmuzxq54XdjeLNmKtX0g/VQ4K2TN552I/dtvE/BT0Qig3ZQEZHj8nhg9263tVp9vRvhC+Y+ugCNB6H4OShbB4k5MPJ6SJse9MDn82r1h3wtdpL7JpyXx/X3T+XlmtSjnuOrk2+8cSbXPndtSPrVUxT8RKJI1O0MICKB4fHArl3ulG5DgxvhS0098eu6o/GAC3wH34TkoTDqBug/NWSBD4DKSupqK0kdPwrOuRz69uXDXe0/dds2MMYQG4Q5huFEwU8kimgHFRE5SmurC3wbN7rAl5np1uILpoZi7wjfW5A8Akb/APpPAROiSyashcpKaGqC8eMZOGAme4akcYZ3ZPN4dbK+uR5LdO+gqOAnEkW0g4qIAC7w7djhJv42NbkRvqAHvv1Q9ByUvw0poyH3Juh3cmgDX0UFNDfDxIlwyimQnMyVJf340cs/4orJVwDHr5OrPlnF4rGLQ9PfHqLgJxJFtIOKSC/X0gLbt8OmTS4AZWRAnyD/V1+/D4qfhfL1kDIGxtwKqZN6JvBNnux+JR9ZsmVy9mRaPC289cVbnDXsrGPWyYlTavnuyn/j6cueDk2/e4iCn0iU0Q4qIr1QS4ub5Ltpkxvty8iA2CDPVavfC0XPQEUB9B0Lef8EfceHPvC1tBwJfElJ7T71fy7+Hy567CL+68L/4sxhZ36lTlY2VHLJ40u4fvr14bXcThAo+ImIiESq5mYX+N59N3SBr26PC3yVmyB1IuT9FFLHB7dNfx6PC3weD5x8MkyaBImJx33JqPRRPH/F81zz7DUk9knk2qnXMiJtBLVNtTz16VO8uvtV/nnWP3PVyVeF6E30HAU/iShanFhEBBf4PvsMNm92Acgb+AoLYeVK2LcfcgbDsmWuVgZE3W7Y/wxUbYZ+k2HsbdA3UAfvAI8HysvdSN+UKTBhwgkDn79R6aNY9611fFj8IY9ueZS/bv8rSX2SmDNyDv86/1+Ji40LYufDh4KfRAwtTiwivV5T05HAZ+1RI3yFhXD77VBT655aWelu33lnN8Nf7U43wlf1PvQ7BcbeAX1zu/1WOswX+OBI4EtI6PLhThl0CqcMOiVAnYs8Cn4SMbQ4sYj0Wk1N8Omn8N577nZGBsQcvR7eypVHQp9PTS08+CAsX96FNmu2Q9HTcOgjt/7euLsgZVTX+t8V/oHv1FNh/HiIjw9d+1FKwU8ihhYnFpFep7ERtm6FDz5wt9sJfD779rd/iC/3dbLNmm2w/2mo/tjtsDH+l249vlBpbXWBzxiYNg3GjVPgCyAFP4kYWpxYRHqNhgb45BP48EMXgI4T+HxyBrvTu20Nyelgm9WfuhG+6q2Qlg/jfwXJwzvf967yBb6YGJgxwwW+uN4x7y6UFPwkYmhxYhGJeg0N8PHHLvDFxrqdNk4Q+HyWLTt6jh9A3xS45prjvMhaqP7EzeGr2Qbpp8GE5ZA0tHvvozN8gS82FmbOhDFjFPiCSMFPIoYWJxaRqFVfD1u2uF99+kBWVqfXw8vLcxdyPPigO707JMeFvnYv7LDWncrd/zTUboeM02HCryGpo8ODAdA28OXlBX+xaVHwk8iixYlFJKrU1R0JfHFxXQp8/vLyTnAhh7Vw6EN3Srd2N2ScASO+DYmDu9xmp7W0uMAXHw9nnAG5uQp8IaS/aRERkVCrrYWPPnLz+OLiYODA4O54Ya1bjqXoabcAc+YsGHE9JA7q5GEsm+t2sKeplDgTy6nJoxkSP6BjL/YPfLNmwejRwV9sWr5CwU9ERCRUamvd/L2tW10ACnrg80DlZjeHr/5LGDAbRv0jJAzs3GGs5cGyV/nP0hcZHp/FxKRhNNkWflH8OEPjBvCzk5YyLfkYa/s1N7vAl5gIs2fDqFEKfD2oW8HPGLMCOA34ArjGWtsUkF6JiEQB1Ug5rKbGLcny2Wdu8eHs7OC2Zz1Q+a4LfA37IPMcGP1DSOjg6Jz/oazl+r33U+dp5PnR/8zg+MyjHttQu41r9/w7vxx8NRf2n3Hkhb7Al5QE554LI0d2+EIVCZ4uBz9jzFRgkLV2ljHmZ8DXgUcD1jMRkQimGikAVFfD+++7hUjj40MT+CoKXOBrLIEB50DuTeAX1jrrvtLnaLGtPDT8B5g2o5PGGE7vO46Xc+9k7vafMy4hh9zYLBf4UlJgzhwYPlyBL4x0Z8TvdOBl75/XAtegoiYRTnsBSwCpRvZmhw65wLd9e4hG+FqhfAMUPwuNpZB1HmT/GOLTu3XYFtvKH0pfYsO4ew+Hvvb3A07jp1mX8p97nuDfhlwLc+fCsGEKfGGoO8EvDfCtE14FZHS/OyI9R3sBS4CpRvZGhw7Bu+/Crl1uTltIAt87UPQsNJXDwLmQvQji0gJy+LWH3mN26kT6x6YA7e8H/MvbmrjjxnIunXwqd8Q+y68vXUxCfFJA2pfA607wqwD6ef+cBpT7HjDGLAGWAMycObMbTYiEjvYClgA7Zo0E1cmoU1kJmzfD7t1uTlvQA18LlL3tAl9LFWTNg+yFENc/oM1sa/iSGcljDt/23w84nkbSqaCqrj8/fm0+q381lGEP/4kD9QcZGh/CBaClU7oT/DYANwF/AuYDb/sesNauBlYDLF261HangyKhor2AJcCOWSNBdTJqVFTApk3wxRehCXyeFih7E4qfg5ZqGHi+C3x9UoPSnMFgOfLPc99+v8BHGmtYyH5yyN5jwIDFEmN0ejecdTn4WWvfN8YUG2PexF2xpo2zJKJpL2AJJNXIKFdefiTwpaSEIPA1Q9k6KHoeWusgez4MXAB9+ga12UlJw3m0fB3fGTAfGhuZNKCSgso0XmQRRQwG3Ly/sWOhvrmevVV7GZjSuaViJLS6tZyLtfbmQHVEpKdpL2AJNNXIKFRe7iYE790LffvCoM4tgNxpniY4+AYUPw+eRhi40I3y9UkJbrtec1NP4Ud7/5uy/TvIHDCM83+7iHuuPomKyiNxED3WAAAbP0lEQVRX9/rq5OOfPM7Xxn2NuFjtsxvOtICziJf2AhaRYyorg40bYf9+N8IX9MDXCKX/ByUvuNO72Qth4DyITQ5uu/7q64mpquIHAy7k+oT/47FLnmJqbB/WvvTVOjlo7Bdc88i9rLlqTej6J12i4CfiR3sBi8hRSkvdCN/+/ZCaGvxTuq0NcPB1KP4r4HFX6GbNhdgQXiVbV+euTs7Kgosv5tqB32bX6z/jklVf456595CfP+FwnWz1tPLi9hdZ9sg/8ftFv2dY/2Gh66d0iYKfiIhIW6WlsH49HDjgAl+wR/haG6D0FSh5ETCQfQFkzYHYxOC2688X+LKz3U4bA91cPQPcPedunv3sWb7/4vfxWA/jB4yn2dPM+i/Xc8aQM3jqsqfIy8wLXV+lyxT8REREfEpKYMMGF/xCMsJXBwdegZI1YGJh0MVu8eWYhOC2688X+AYNgvPOcyN97Vg8bjGLxy1mV8Uu9lTuIT42nhXnryAtMTBrBkpoKPiJiIgUF7vAd/Ag9OsX/MDXUgulL0PJWoiJh8GXuu3VYuKD266/2lq3pdzgwW5rtQEd28d3VPooRqWPCnLnJFgU/EREpHeyFoqKXOArL4f+/UMT+A6shQMvQUwiDP46DDg7tIGvpsb9ysmBefMgs+v7+ErkUfATEZHexVp3scb69W7HjZAEvmo3unfgJbf2Xs7lkDkLYkK49Ikv8A0dCvPnQ4Z2EeyNFPxERKR3sBb27TsS+NLTgx/4mg/BgTVuHl+fVBh6NWScBTEh/O+3utqd1h0+3C1Wmp4eurYl7Cj4iYhIdLMWvvzSBb5DhyAtLfhX6TZXQclfofQ1iEuDYd+EjDPAhPC/3UOH3IUbI0bAokXufUuvp+AnIiLRyVq3pdqGDW7UKyQjfBVuDb7S1yE+E4ZdAxmnuyt2Q8UX+EaNgunT3alsES8FPxERCYjS2lIO1B4gKS6J4f2HExsTwrDjz+M5EvhqakIT+JrKofgFOPh/kDAQRnwH0k8DExPcdv1VVUF9PeTmwrRp7upkkTYU/EREpFvWbF/D7wp+x8G6g4xIG0FtUy17qvZw9eSr+fvpf096UojmlHk8sGePC3y1te7ihaAHvoPewPcGJAyCkX8PaTNCG/gqK6GhAfLy4NRT3fqDIseg4CciIl1ireWml29iR/kOfnXerzj1pFMPP1bZUMnK91dyzkPn8OzlzzIibUTwOuLxwO7dbi/d+no3wte3b/DaA2gsheLnoOxvkJgDI78HadNCG/gqKqCpyQW+qVMV+KRDFPxERKRL/mX9v1BWX8Yzlz9DTJvAk5aYxo9O/xHTTprG1x7/Gu8se4ekuADvN9va6gLfhg1uxCsjI/jhp/EAFD0LZW9B8jAYdQP0PxWMCW67Pta6U7qNjTBuHEyZEvyQK1ElhF9NIltBAcye7S4Emz3b3RYR6a3qm+v543t/5IELHjgc+tqrk2ePOJv5o+ez6pNVgWu8tRUKC+Gxx+CNNyAlxZ3SjQvimngNxfD5H+Djm6H+S8j9AYy7yzvKF4LQZ60b4TtwAEaPhiuugLPOUuiTTtOIXwcUFLiljyoq3O2SEnd77VrIz+/ZvomI9IQntj7B4rGLD4/iHa9OXjftOq566ir+bsrfda/R1lbYscM11tTkRviCfcVqw343wlf+DqTkQu7N0G9yaEf4KiqguRkmTYKTT4bk5NC0LVFJwa8Dbr75SDHzqaiAW26Bdet6pk8iIj1pc9FmFuQuOHz7+HVyJJUNlVhrMV0JTC0tsH07bNrkAlBmJsQG+Yrh+n1Q9AxUbIC+Y2DMjyF1Ys8EvsmTXeBLCvCpcumVFPw6oLCw/fu3bQttP0REwkWLp4U+frtPnKhOxpgYLBZDJ4JTc/ORwNfa6kb4gh749kLR01CxCfqOg7x/gr7jQx/4Wlpc4Js8WYFPAkrBrwPy8txpi7bGjg19X7qjoMB9Ky8sdO9pxQqdqhaRrhmdPpotJVuYO2oucPw6WdVQhTHmKxeAHFNzs0uMmzeHLvDV7XEjfJWb2F4yicf/9jNqGMeyZe69BZ3H4wJfa6u7YGPiREhMDEHD0tso+HXAihVHz10Bt1rAvff2XJ86S/MURSSQrjr5Kub+aS43zryRGBNz3Dr50IcPceWkK0980OZm+OwzF/g8ntAEvtrdboSv6j1qYydzz6O38f72I0nv9tvhzjuDGP48Higvd38+5RQX+BISgtSYiK7q7ZD8fBeQZs92F47Nnh15gel4829ERDprYMpA8nPyuX/T/cCx62TOuH088O4DXHvqtcc+WFMTfPQRPPywO62blgZZWcENfbU7YccK+OzngAfG3cEv/vLjo0IfQE0tPPhgENr3eKCszIW+qVPhyivd4ssKfRJkGvHroPz8yL6QQ/MURSTQ7ltwHwsfWUhtcy03nHYD+fmJR9XJzfs3s/CRa/jdwt8xMGXgVw/Q2Aiffgrvv+9uZ2RATJDHI2q2Q9FTcGiLW39v3C8gZSQA+/a3/5Iv9wWwfV/gM8ZtqzZuHMTHB7ABkePrUvAzxqQCrwITgZnW2o8D2isJuGiZpygSKXpDnUyJT+Glq1/ijjfuYMoDU1iYu5DRGaOpbarlucLn6JfQj5WLVzJ98PSjX9jYCFu3wgcfuNuhCHzVn7k5fNUfuy3Vxv8Skkcc9ZScwW73s7aG5ASg/dZWN7oXEwMzZrjAF8x1B0WOoasjfvXAhUAEzXLr3aJhnqJIhOkVdTIpLol75t3DHefcwZodayiqLiIrJYuHLnmI3Izco5/c0ACffAIffuhGvIId+KyFmk9h/9NQ8xmkz4Dxd7sdN9qxbJmb01dTe+S+vilwzTXd6IMv8MXGulNHY8cq8EmP6lLws9a2AKVdWo9JeoRv/s0tt7jTu2PHutAXSfMURSJJb6uTSXFJXDr+0vYfbGiALVvcPL4+fWDAgOAuj2ItVH/iLtqoKYT002DCckgactyX5eW5CzkefNCd3h2S40Jfly7s8A98M2fCmDEKfBIWNMevF4n0eYoiEmHq613Y+/hjF/iysoIf+A5tcYGvdgdknAETr4XEwR0+RF4eLF/ejT60tro5fHFxcPrpLvD10X+1Ej6O+6/RGDMIeKKdhy621pYf53VLgCUAM2fO7FYHRUTCmepkO+rqXOD75JMQBr4PYP8zULcbMs+EEd+FxJOC12ZbLS1uhC8+3u2hO3q0Ap+EpeP+q7TWFgNndfag1trVwGqApUuX2q51TUQk/KlO+qmtPRL44uNDE/iq3nMXbdR9AZlnwah/gITs4LXZVkuLG+FLTIRZs1zgC/bagyLd0OWvI8aYF4EpwFhjzB+stf8bsF6JiESBXlMna2vdkizbtrnAN3BgkAOfByo3u8DX8CVkzoZR/wgJ7SwZEyzNzW6ELzERzjkHRo5U4JOI0OXgZ61dFMiOiIhEm6ivkzU18N57LvAlJLjAF0zWA5WbvIGvCAacDbk/hPgBwW3XX3OzWx4hKQnOPdcFvmAvRSMSQJqAICIinVNd7QJfYaEb8Ro0KLjtWQ9UbHSBr/EADDgXcm+G+MzgtuvPN8KXkgLnnQfDhyvwSURS8BMRkY45dMgFvh07QhT4WqF8PRQ9C00HIWsODLoA4tKD266/piY3wte3L8ydC8OGKfBJRFPwExGR46uqgs2bYedOSE52m/EGk22F8reh6DlornCBL3sRxKUFt11/TU1uhK9fP5g3D4YOVeCTqKDgJyIi7aushHffhd27XeAL+ghfC5S95QJfSxVkzYPshRDXP7jt+mtsdCN8/fvD/Pku8PWSRbild1DwExGRo1VUwKZNsGePm9MW7MDnaYGyv0Hxc9BSAwPnQ/YC6JMa3Hb9+QJfWhosXAg5OQp8EpUU/ERExCkvh4IC2Ls3RIGvGQ6+AcUvgKfeBb6B86FP3+C266+x0Y1spqXBokUweLACn0Q1BT8Rkd6urAw2boR9+9xFDEEPfE3ewPe8+3P2Asg6H/qkBLddfw0Nbu5iRoYLfCedpMAnvYKCn4hIb3XwoAt8RUUhCnyNUPq6G+GzrW7+3sB5EJsc3Hb91de7q5MzM+HCC4P/nkXCjIKfiEhvU1oKGzZAcbG7ajXYV+m2NkDpa1DyV8C6K3Sz5kJsUnDb9VdX5wJfVhZcdFHw37NImFLwExHpLQ4ccIGvpMQFvmCPdrXWQ+krULIGMDDoQhhwHsQmBrddf77Al53tdtoI9u4iImFOwU9EJNqVlMD69W6kLySBrw4OeAOfiYVBiyHrXIhJ6NLhrLVsrNvG70vX8F7dTjxYhsUP4NrMeVySNpM4085/Zb7Ad9JJbqeNrKxuvimR6KDgJyISrYqK3AhfWVloAl9LLRx4GQ6scSFv8KUw4ByIie/yIQ+11nH57nuJN334XtYiVg6/gVhi2Nqwlz8cXMtdRY/z2MibmZQ03L2gttZtKZeTA3PmwIAQ7uMrEgEU/EREoom1LvCtX39kIeJgz2drqYEDa6HkJXehRs5SyDwbYuK6ddhGTzMX7/wl38qcw7cy5xz12MSkYfxu6Hf5qG43S3f/hucG/ZDcpr4wZIjbaSMzhPv4ikQQBb8wUVAAN9/s9jzPy4MVKyA/v6d7JSIRw1rYv98FPt+6dEEPfNXudO6Bl91iy0OuhMxZEBOY/1r+VP46+cljDoe+wkJYuRL27YecwbBsGZw8OIvfJl/KTw89zaqrnnHLs4jIMSn4hYGCAliwwH05BzcdZ8ECWLtW4U9ETsBat/6eL/Clpwc/8DVXucBX+gr06Q9DvwGZZ0J7c+26yFrLfx18iadH/RRwoe/226Gm1j3eUlnNf95Wy/XLhzPv6tv4yeq57I9rYHDAeiASnRT8wsDNNx8JfT4VFXDLLbBuXc/0SUTCnLVuh40NG9xCxOnpwZ/D11wJJS+6pVni0mHYtyDjDHcBR4Dtby4nJSaRIfFujt7KlS70pXKIZOrYzUjW1E3ngyfTWHcDfH3C13lpx0tcM/WagPdFJJoo+IWBwsL279+2LbT9EJEI4PG4wLd+PdTUhCbwNVVAyQtu8eWELBi2DDJmBiXw+RxqrSMj9sjWbYe+rCKbenYxis1M5xD9gSN1MiMpg+qm6qD1RyRaKPiFgbw8d3q3rbFjQ98XEQlTHg988YUb4fMFvmCf0m0qc7tsHHwDErJhxHWQng8mJrjtAhl9+lLcUulGMxsa6DM8l4e3nEo1/Y56nq9OFlUXMSZzTND7JRLpFPzCwIoVR8/xA1fT77235/okImHC44E9e1zgq611Fy8EPfAdhKLnoWwdJJ4EI6+HtOkhCXw+2TUQ19xK4QBD3pmXcfXJqTy8AGinTrZ6Wnny0yd585o3Q9Y/kUgVuk+xHFN+vruQY/ZsV89nz9aFHSK9nscDO3fCY4/Ba69BQoIrEHHdWyLluBpLYc//wMc3Qe0OGPk9GP+rkI3yAe4bcHExjBjB9fN+yj2Nr0Nq6nHr5KpPVpGfk096Unpo+igSwTTiFyby83Uhh4gAra2we7cb4WtocCN8/fqd+HXd0VgCRc9B2VuQPAxG3Qj9p4IxwW3Xx1p3RXJzM4wbB1OmQEoKS+1ZPLn7r9z5xp3cdvZt5Oebr9TJV3a+wvK3lvPKN14JTV9FIpyCn4hIOGhtdSN8BQUu8GVmusWXg6mhCIqfg7K3IWUk5P4Q+p0S2sBXUeEC38SJcPLJkJJy+OEYE8Mjlz7CjWtuJP+/8/nuqd9lzqg5xMXEseXAFh549wGqGqtYc9UasvsG+fS3SJRQ8BMR6WnV1fDooy4ApacHP/DV74PiZ6F8PaTkwphbIHVSzwS+SZNc4EtObvep8bHx3H/h/eyt2ssf3/sj/7jmH2lubWZk2kh+PvvnzMiZEZo+i0SJLgU/Y8w04LeABygBrrLWNgeyYyIikaxTdfLAAUhNhdjgLY8CQP2XUPQMVGyEvnkw5seQOjH0ga+l5UjgS0rq0EuH9h/KXefeFeQOikS/ro747QPmW2vrjDF3A5cAqwPXLRGRiNfxOhkTE9zQV/eFC3yVmyB1POT91P0eKtZCebm7YGXyZPcrMTF07YvIYV0KftbaYr+bzUBLYLojIhIdwqJO1n3uDXzvulO5eT+D1HGha9/jcYHPWjjlFDePT4FPpEd1a46fMWYYMBf4ZZv7lwBLAGbOnNmdJkREIlqH6uSoUYFttHYXFD0NVe9Dv5Nh7O3QN4SLG/sCH7grdCdMcMvRiEiPO27wM8YMAp5o56GLcd9e/wxc03beirV2Nd5TGkuXLrWB6aqISPgJSJ2cMSMwdbJ2B+x/Gg596JZjGXcnpIwOyKE7xD/wTZ0K48cr8ImEmeMGP++pirPa3m+MiQWeAe6y1h5jp1kRkegXFnWyptCN8B3aAv2nwbhfuOVZQqW11QU+Y2DaNLcWX3x86NoXkQ7r6qnepcAZQKox5ufA/dbaxwPXLRGRiBf8Oln9mQt81Z9A2gy3y0by8IA2cVy+wBcTAzNmuMAXzJ1FRKTbunpxx2PAYwHui4hI1AhanbQWaj6F/U9BzTa3ndqE5ZA0NOBNHZMv8MXGum2Hxo5V4BOJEFrAWUQkElgL1R+7Eb6a7ZBxOkz4NSTlhK4P/oFv5kzIy4M++m9EJJLoEysiEs6shUMfuWVZandAxpkw8duQOLjTh2q1rTTaFpJMPKYziza3tkJZmRvVO/10GDNGgU8kQumTKyISjqyFqg/cCF/d55B5Joy4DhIHdeowTZ5mnqpcz/0H13Cw5RBJMQlUtdZyfupU/iFrEROThh37xS0tboQvPh7OOgtyc4O/u4iIBJWCn4hIOLEWqt7zBr69kHkWjPo+JAzs9KHKW6q5ZNevOCVpJP817HuMTRwCQLNt4fnKAq7Zcx/fyDiXfxx44dEvbGlxI3yJiTBrFowercAnEiUU/EREwoH1uB02ip6Bhn2QeTaMuhESsrp0uBbbyiW7fsX3BlzAZRmzjnoszvTh0vQzWNh/GpfsvJv02BSuzjwXmpvdCF9iIpxzDowcqcAnEmWiJvgVFMDNN0NhoZtvvGKFu9hMRCTstVTC1p9CYzEMOAdyb4L4zG4d8rnKjUxMHHY49BUWwsqVsG8/5AyGZcsgLy+Bv4y8hTO33crlLePok9wXzj3XBb6YmAC8MREJN1ER/AoKYMECqKhwt0tK3O21axX+RCQCNH0B/S6G7FshPiMgh/z9wTXcN+Q7gAt9t98ONbXuscpKd/uunzczJrOW2YljeWGM5ZJZlyvwiUS5qPiE33zzkdDnU1EBt9zSM/0REemUpPEw9JsBC33WWvY1lR2+cGPlyiOhDyCOJpJrS3j0f5tg7lwuXHADbzYUKvSJ9AJR8SkvPMZmSNu2hbYfIiJdYgK7+LHFEmuOlPd9+93vcTQxkBJiaeUV5vFA+VIYMYKk+BQaWxsD2gcRCU9Rcao3L8+d3m1r7NjQ90VEpKfFmBharYd6TyNJMQkMH9RIfGUlh+jHWhawnxzAMHuce/728u3kpIZwIWgR6TFRMeK3YgWkpx99X3o63Htvz/RHRKSnLU47jVWlb0BxMX/3TcuGfgt4giXsZwhgDtdIay0r31/JVSdf1dNdFpEQiIrgl5/vLuSYPRuys93vurBDRHqthgauYxr/cvB5qubNYsxPvs6Drwxh9mzzlRr51KdPMaTfEIb1P85CziISNaLiVC+4ArZuXU/3QkSkBzU0QFUVZGQwcvG3uOVADhe8/m1WL1lNfv5JR9VIay2rP3mCu9+6m5evfrnn+iwiIRU1wU9EpNeqr3eBLysLLrwQBrlt3b5x0jfpn5jGgkcWMGngJBaPXUxKXAo7K3by0IcPkZuRyyvfeIUByQN6+A2ISKgo+ImIRKq6OqiudoFv8WIY+NVt3S4eezEX5V3E67tf543P36ChpYGTUk/i+SueZ3Dq4B7otIj0JAU/EZFIU1cHhw65kb3zznPB7ziMMcwZNYc5o+aEqIMiEq4U/EREIkVtrRvhGzwY5syBATpFKyKdo+AnIhLuamrcr5wcmDcPMru3j6+I9F4KfiIi4aqmxo3wDRsG8+dDRmC2dBOR3kvBT0Qk3FRXu9O6w4cr8IlIQCn4iYiEi0OH3IUbI0bAokWQltbTPRKRKKPgJyLS01pbobgYRo2C6dOhf/+e7pGIRKkuBT9jzCTgD0ALUANcZq2tCWTHREQiWafqZEYGXHYZ9OsXwh6KSG/U1b16t1lrz7TWng0UAF8LYJ9ERKJBx+tkRoZCn4iERJeCn7W22e9mMvBZYLojIhIdVCdFJBx1eY6fMWYe8BugGbinzWNLgCXem7uMMZu73MPOGwJ8GcL2Qila31u0vi/Qewuk0SFsKyDCtE7q32Rk0nuLTGFXJ4219tgPGjMIeKKdhy621pZ7n3MrEGOt/XVXexlIxphV1tqlPd2PYIjW9xat7wv03nqDSKuT0fxz03uLTHpvoXXcET9rbTFwVtv7jTEJfjergPgA90tEJCKoTopIJOnqqd55xphbAA9QCnwrYD3qvtU93YEgitb3Fq3vC/TeerNwrZPR/HPTe4tMem8hdNxTvSIiIiISPbq6nIuIiIiIRJioDX7GmCuMMaU93Y9AMsZMM8a8aYxZZ4xZZYyJ6+k+dZcxZoX3PT1ijImaOVDR+LNqKxo/Y71NNP4Mo/GzpzoZucLxMxaVwc8YEwN8Hdjb030JsH3AfO+CsDuAS3q4P91ijJkKDLLWzgK24n5m0SKqflZtRfFnrNeI4p9hVH32VCcjV7h+xqIy+AFX4pZX8PR0RwLJWltsra3z3mzGbQUVyU4HXvb+eS1wRg/2JaCi8GfVVlR+xnqZqPwZRuFnT3UycoXlZyzqgp8xJhZYCjze030JFmPMMGAu8EJP96Wb0oBD3j9XARk92JegiKKf1WG94TMW7XrDzzCKPnuqkxEonD9jXd65o6cdZ9HUPwKrrLUeY0yIexUYx1sQFveN6M/ANW22hIpEFYBvg9I0oLwH+xJwxph+RM/Pyt/VRPhnrLdQnYyKz57qZGQK2zoZdcu5GGPuAabihlZPB1Zaa3/Ys70KDO83iGeA31prX+vp/nSXd+7KTdbaq40xPwN2WWsf6+l+BUK0/az8RfNnrLeI5p9htH32VCcjUzh/xqIu+PkzxrxrrZ3e0/0IFGPMFcB/AFu8d91vrQ27YeTOMMasAE4DvsB942vq4S4FRDT+rNoTbZ+x3ijafobR+NlTnYxs4fYZi+rgJyIiIiJHRN3FHSIiIiLSPgU/ERERkV5CwU9ERESkl1DwExEREeklFPxEREREegkFPxEREZFeQsFPREREpJf4/4x+9TfKggwwAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 780x240 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import warnings\n",
    "import logging\n",
    "import sys\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# convert warnings to error\n",
    "warnings.filterwarnings(\"error\")\n",
    "\n",
    "def getLogger(name):\n",
    "    logger = logging.getLogger(name)\n",
    "    if len(logger.handlers) == 0:\n",
    "        handler = logging.StreamHandler(sys.stdout)\n",
    "        formatter = logging.Formatter('%(message)s')\n",
    "        handler.setFormatter(formatter)\n",
    "        logger.addHandler(handler)\n",
    "        logger.setLevel(logging.WARNING)\n",
    "    return logger\n",
    "\n",
    "logger = getLogger(\"SMO for Regression\")\n",
    "\n",
    "MAX_DEPTH = 20\n",
    "SPLIT_SECTIONS = 10\n",
    "\n",
    "f = lambda x: .3*x\n",
    "\n",
    "kernel = lambda x, y: x@y\n",
    "\n",
    "def gen_data(n):\n",
    "    noise = np.random.normal(0, .8, n)\n",
    "    X = np.linspace(-4, 4, n)\n",
    "    T = f(X) + noise\n",
    "    return X.reshape(-1, 1), T\n",
    "\n",
    "def draw_points(ax, X, T):\n",
    "    for i in range(len(T)):\n",
    "        ax.scatter(X[i][0], T[i], s=50, color='blue')\n",
    "    return\n",
    "\n",
    "class SMO:\n",
    "    A = None\n",
    "    X = None\n",
    "    T = None\n",
    "    E = None\n",
    "    b = 0.0\n",
    "    C = 0.0\n",
    "    epsilon = 0.0\n",
    "    eps = 1e-4\n",
    "    \n",
    "    def __init__(self, X, T, C, epsilon):\n",
    "        length = len(T)\n",
    "        self.X = X\n",
    "        self.T = T\n",
    "        self.C = C\n",
    "        self.epsilon = epsilon\n",
    "        # linear equality\n",
    "        self.A = np.zeros(length)\n",
    "        self.A[:length//2] = C/2\n",
    "        self.A[length//2:length//2*2] = -C/2\n",
    "        \n",
    "        ynb = np.zeros(length)\n",
    "        for i in range(length):\n",
    "            ynb[i] = self.A@kernel(X, X[i])\n",
    "        self.b = np.sum(T - ynb)/length\n",
    "        self.E = ynb + self.b - T\n",
    "        logger.info(\"Initialize \\n A = {} \\n b = {} \\n E = {}\".format(self.A, self.b, self.E))\n",
    "        return\n",
    "    \n",
    "    def meet_KKT(self, i):\n",
    "        # from the equation y = A @ kernel(X, x) we can find that X will expand the errors\n",
    "        eps = self.eps*len(self.T)\n",
    "        epsilon = self.epsilon\n",
    "        y = self.A @ kernel(self.X, self.X[i]) + self.b\n",
    "        logger.info(\"A[{}] = {} t = {}, y = {}\".format(i, self.A[i], self.T[i], y))\n",
    "        if abs(self.A[i])<eps and abs(self.T[i] - y)<epsilon:\n",
    "            return 1\n",
    "        if abs(self.A[i])>0 and abs(self.A[i])<self.C and abs(abs(self.T[i]-y)-epsilon)<eps:\n",
    "            return 1\n",
    "        if abs(self.A[i]-self.C)<eps and abs(self.T[i]-y)>epsilon:\n",
    "            return 1\n",
    "        return 0\n",
    "    \n",
    "    def optimize(self, i, j):\n",
    "        if i==j:\n",
    "            return 0\n",
    "        a1 = self.A[i]\n",
    "        a2 = self.A[j]\n",
    "        x1 = self.X[i]\n",
    "        x2 = self.X[j]\n",
    "        t1 = self.T[i]\n",
    "        t2 = self.T[j]\n",
    "        E1 = self.E[i]\n",
    "        E2 = self.E[j]\n",
    "        C  = self.C\n",
    "        b  = self.b\n",
    "        k11 = kernel(x1, x1)\n",
    "        k22 = kernel(x2, x2)\n",
    "        k12 = kernel(x1, x2)\n",
    "        eps = self.eps\n",
    "        epsilon = self.epsilon\n",
    "        s1 = np.sign(a1)\n",
    "        s2 = np.sign(a2)\n",
    "        w = a1 + a2\n",
    "        \n",
    "        L = max(-C, w-C)\n",
    "        H = min(C, w+C)\n",
    "        if L==H:\n",
    "            logger.info(\"[{},{}] L==H={}\".format(i, j, L))\n",
    "            return 0\n",
    "        eta = k11 + k22 - 2*k12\n",
    "        \n",
    "        if eta>0:\n",
    "            if w > 0:\n",
    "                cand_a2_new = a2 + (E1-E2+epsilon*(2))/eta\n",
    "                if cand_a2_new <= L:\n",
    "                    a2new = L\n",
    "                elif cand_a2_new < 0:\n",
    "                    a2new = cand_a2_new\n",
    "                else:\n",
    "                    cand_a2_new = a2 + (E1-E2+epsilon*(0))/eta\n",
    "                    if cand_a2_new <= 0:\n",
    "                        a2new = 0\n",
    "                    elif cand_a2_new < w:\n",
    "                        a2new = cand_a2_new\n",
    "                    else:\n",
    "                        cand_a2_new = a2 + (E1-E2+epsilon*(-2))/eta\n",
    "                        if cand_a2_new <= w:\n",
    "                            a2new = w\n",
    "                        elif cand_a2_new < H:\n",
    "                            a2new = cand_a2_new\n",
    "                        else:\n",
    "                            a2new = H\n",
    "            elif w < 0:\n",
    "                cand_a2_new = a2 + (E1-E2+epsilon*(2))/eta\n",
    "                if cand_a2_new <= L:\n",
    "                    a2new = L\n",
    "                elif cand_a2_new < w:\n",
    "                    a2new = cand_a2_new\n",
    "                else:\n",
    "                    cand_a2_new = a2 + (E1-E2+epsilon*(0))/eta\n",
    "                    if cand_a2_new <= w:\n",
    "                        a2new = w\n",
    "                    elif cand_a2_new < 0:\n",
    "                        a2new = cand_a2_new\n",
    "                    else:\n",
    "                        cand_a2_new = a2 + (E1-E2+epsilon*(-2))/eta\n",
    "                        if cand_a2_new <= 0:\n",
    "                            a2new = 0\n",
    "                        elif cand_a2_new < H:\n",
    "                            a2new = cand_a2_new\n",
    "                        else:\n",
    "                            a2new = H\n",
    "            elif w == 0:\n",
    "                cand_a2_new = a2 + (E1-E2+epsilon*(2))/eta\n",
    "                if cand_a2_new <= L:\n",
    "                    a2new = L\n",
    "                elif cand_a2_new < 0:\n",
    "                    a2new = cand_a2_new\n",
    "                else:\n",
    "                    cand_a2_new = a2 + (E1-E2+epsilon*(-2))/eta\n",
    "                    if cand_a2_new <= 0:\n",
    "                        a2new = 0\n",
    "                    elif cand_a2_new < H:\n",
    "                        a2new = cand_a2_new\n",
    "                    else:\n",
    "                        a2new = H\n",
    "\n",
    "            logger.info(\"[{},{}] a2new = {} L = {}, H = {}\".format(i, j, a2new, L, H))\n",
    "            logger.info(\"eta = {}, E = {}\".format(eta, self.E))\n",
    "        else:\n",
    "            raise Exception(\"second derivative non-positive!\")\n",
    "        if abs(a2 - a2new) < eps:\n",
    "            logger.info('[{},{}] L={}, H={}, a2new={}'.format(i, j, L, H, a2new))\n",
    "            logger.info('[{},{}] eta {} error {}'.format(i, j, eta, self.E))\n",
    "            logger.info(\"[{},{}] a2==a2new = {}\".format(i, j, a2new))\n",
    "            return 0\n",
    "        a1new = a1+a2-a2new\n",
    "        self.A[i] = a1new\n",
    "        self.A[j] = a2new\n",
    "        \n",
    "        n = 0\n",
    "        b1new = 0\n",
    "        b2new = 0\n",
    "        \n",
    "        if (a1new > 0 and a1new < C) or (a1new == C and E1 > -epsilon):\n",
    "            b1new = -E1 - (a1new-a1)*k11 - (a2new-a2)*k12 - epsilon + b\n",
    "            n = 1\n",
    "            logger.info(\"[1 update b {},{}] a1 new {} non bound, error = {}\".format(i, j, a1new, E1))\n",
    "        elif (a1new < 0 and a1new > -C) or (a1new == -C and E1 < epsilon):\n",
    "            b1new = -E1 - (a1new-a1)*k11 - (a2new-a2)*k12 + epsilon + b\n",
    "            n = 1\n",
    "            logger.info(\"[2 update b {},{}] a1 new {} non bound, error = {}\".format(i, j, a1new, E1))\n",
    "        elif (a2new > 0 and a2new < C) or (a2new == C and E2 > -epsilon):\n",
    "            b2new = -E2 - (a1new-a1)*k12 - (a2new-a2)*k22 - epsilon + b\n",
    "            n = 1\n",
    "            logger.info(\"[3 update b {},{}] a2 new {} non bound, error = {}\".format(i, j, a2new, E2))\n",
    "        elif (a2new < 0 and a2new > -C) or (a2new == -C and E2 < epsilon):\n",
    "            b2new = -E2 - (a1new-a1)*k12 - (a2new-a2)*k22 + epsilon + b\n",
    "            n = 1\n",
    "            logger.info(\"[4 update b {},{}] a2 new {} non bound, error = {}\".format(i, j, a2new, E2))\n",
    "        elif (a1new == 0 and abs(E1) > epsilon):\n",
    "            b1new = -E1 - (a1new-a1)*k11 - (a2new-a2)*k12 + b\n",
    "            n = 1\n",
    "            logger.info(\"[5 update b {},{}] a1 new {}, error = {}\".format(i, j, a1new, E1))\n",
    "        elif (a2new == 0 and abs(E2) > epsilon):\n",
    "            b2new = -E2 - (a1new-a1)*k12 - (a2new-a2)*k22 + b\n",
    "            n = 1\n",
    "            logger.info(\"[6 update b {},{}] a2 new {}, error = {}\".format(i, j, a2new, E2))\n",
    "        else:\n",
    "            b1new = b\n",
    "            n=1\n",
    "\n",
    "#         if a1new > -C and a1new < C:\n",
    "#             b1new = -E1 - (a1new-a1)*k11 - (a2new-a2)*k12 + b\n",
    "#             n = 1\n",
    "#             logger.info(\"[{},{}] a1 new non bound\".format(i, j))\n",
    "#         elif a2new > -C and a2new < C:\n",
    "#             b2new = -E2 - (a1new-a1)*k12 - (a2new-a2)*k22 + b\n",
    "#             n = 1\n",
    "#             logger.info(\"[{},{}] a2 new non bound\".format(i, j))\n",
    "#         else:\n",
    "#             b1new = -E1 - (a1new-a1)*k11 - (a2new-a2)*k12 + b\n",
    "#             b2new = -E2 - (a1new-a1)*k12 - (a2new-a2)*k22 + b\n",
    "#             n = 2\n",
    "#             logger.info(\"[{},{}] a1 new a2 new bound\".format(i, j))\n",
    "        bnew = (b1new + b2new)/n\n",
    "        self.b = bnew\n",
    "        \n",
    "        for k in range(len(self.X)):\n",
    "            self.E[k] = self.E[k] + (a1new-a1)*kernel(x1, self.X[k]) + (a2new-a2)*kernel(x2, self.X[k]) + (bnew - b)\n",
    "        return 1\n",
    "\n",
    "    def pair_optimize(self, i):\n",
    "        length = len(self.T)\n",
    "        j = np.argmax(np.abs(self.E[i] - self.E))\n",
    "        update = self.optimize(i, j)\n",
    "        if update==1:\n",
    "            logger.info(\"[{},{}] A = {}\".format(i, j, self.A))\n",
    "            return update\n",
    "        for j in range(length):\n",
    "            if self.A[j]>-self.C and self.A[j]<self.C:\n",
    "                update = self.optimize(i, j)\n",
    "                if update == 1:\n",
    "                    logger.info(\"[{},{}] A = {}\".format(i, j, self.A))\n",
    "                    return update\n",
    "        for j in range(length):\n",
    "            if self.A[j]<=-self.C or self.A[j]>=self.C:\n",
    "                update = self.optimize(i, j)\n",
    "                if update == 1:\n",
    "                    logger.info(\"[{},{}] A = {}\".format(i, j, self.A))\n",
    "                    return update\n",
    "        return 0\n",
    "\n",
    "    def train(self):\n",
    "        length = len(self.T)\n",
    "        finished = 0\n",
    "        initialized = 1\n",
    "        count = 0\n",
    "        while finished != 1:\n",
    "            count += 1\n",
    "            if count == 1000:\n",
    "                logger.warning(\"too long!!!!!\")\n",
    "                break\n",
    "            if initialized==1 or validation==1:\n",
    "                initialized = 0\n",
    "                validation = 0\n",
    "                update = 0\n",
    "                for i in range(length):\n",
    "                    update = self.pair_optimize(i)\n",
    "                if update == 0:\n",
    "                    finished = 1\n",
    "            else:\n",
    "                while True:\n",
    "                    # find the multiplier that violate KKT condition\n",
    "                    idx = -1\n",
    "                    update = 0\n",
    "                    for i in range(length):\n",
    "                        if self.A[i]>-self.C and self.A[i]<self.C:\n",
    "                            is_kkt = self.meet_KKT(i)\n",
    "                            logger.info(\"[{}] non bound update meet KKT:{}\".format(i, is_kkt))\n",
    "                            if is_kkt==0:\n",
    "                                idx = i\n",
    "                                update += self.pair_optimize(i)\n",
    "                    # if update == 0, means the parameter a could already be the best, then update the threshold b\n",
    "                    if update == 0:\n",
    "                        b = self.b\n",
    "                        bnew = 0.0\n",
    "                        n = 0\n",
    "                        for k in range(len(self.A)):\n",
    "                            if abs(self.A[k]) > 0 and abs(self.A[k]) < self.C:\n",
    "                                bnew += self.T[k] - self.A@kernel(self.X, self.X[k])\n",
    "                                n += 1\n",
    "                        if n != 0:\n",
    "                            bnew = bnew/n\n",
    "                            self.b = bnew\n",
    "                            self.E = self.E - b + bnew\n",
    "                    # if all non-bound multipliers meet the KKT conditions\n",
    "                    if idx == -1:\n",
    "                        break\n",
    "                validation = 1\n",
    "        return\n",
    "\n",
    "    def draw(self, ax):\n",
    "        epsilon = self.epsilon\n",
    "        logger.info(\"lagrange multiplier {}\".format(self.A))\n",
    "        x = np.array([-5, 5])\n",
    "        y = np.zeros(x.shape)\n",
    "        w = self.A@self.X\n",
    "        logger.info(\"w = {}, b = {}\".format(w, self.b))\n",
    "        y[0] = self.b + w[0] * x[0]\n",
    "        y[1] = self.b + w[0] * x[1]\n",
    "        ax.plot(x, y, color='C1')\n",
    "        \n",
    "        ax.fill_between(x, y-epsilon, y+epsilon, color='r', alpha=.3)\n",
    "        \n",
    "        for i in range(len(self.T)):\n",
    "            if abs(self.A[i]) > 1e-10:\n",
    "                ax.scatter(self.X[i][0], self.T[i], s=200, edgecolors='green', facecolors='none')\n",
    "        return\n",
    "\n",
    "def sklearn_SVR(ax, X, T, C, epsilon):\n",
    "    svr = SVR(kernel='linear', C= C, epsilon=epsilon)\n",
    "    svr.fit(X, T)\n",
    "    n = np.sum(svr.n_support_)\n",
    "    w = svr.coef_.reshape(-1, 1)\n",
    "    idxs = svr.support_\n",
    "    a = svr.dual_coef_.reshape(-1,1)\n",
    "    b = svr.intercept_ \n",
    "    y = svr.predict(X[idxs])\n",
    "    logger.info(\"a = {}\\n idxs = {}\\n w = {}\\n b={}\".format(a, idxs, w, b))\n",
    "    \n",
    "    x = np.array([-5, 5])\n",
    "    y = np.zeros(x.shape)\n",
    "    y[0] = b + w[0] * x[0]\n",
    "    y[1] = b + w[0] * x[1]\n",
    "    ax.plot(x, y, color='C1')\n",
    "    \n",
    "    ax.fill_between(x, y-epsilon, y+epsilon, color='r', alpha=.3)\n",
    "    \n",
    "    ax.scatter(X[idxs], T[idxs], s=200, edgecolors='green', facecolors='none')\n",
    "    return\n",
    "\n",
    "def main():\n",
    "    fig = plt.figure(figsize=(13,4), dpi=60)\n",
    "    ax1 = fig.add_subplot(1,2,1)\n",
    "    ax2 = fig.add_subplot(1,2,2)\n",
    "    X, T = gen_data(10)\n",
    "    xmin = -5\n",
    "    xmax = 5\n",
    "    ymin = -3\n",
    "    ymax = 3\n",
    "    ax1.set_xlim(xmin, xmax)\n",
    "    ax1.set_ylim(ymin, ymax)\n",
    "    ax2.set_xlim(xmin, xmax)\n",
    "    ax2.set_ylim(ymin, ymax)\n",
    "    ax1.set_title(\"Hand-made SVR\")\n",
    "    ax2.set_title(\"sklearn SVR\")\n",
    "    draw_points(ax1, X, T)\n",
    "    draw_points(ax2, X, T)\n",
    "\n",
    "    C = 10\n",
    "    epsilon = .5\n",
    "    \n",
    "    sklearn_SVR(ax2, X, T, C, epsilon)\n",
    "    \n",
    "    smo = SMO(X, T, C, epsilon)\n",
    "    smo.train()\n",
    "    smo.draw(ax1)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "C = 6\n",
    "length = 11\n",
    "A = np.zeros(length)\n",
    "print(length//2)\n",
    "A[:length//2] = C//2\n",
    "A[length//2+1:] = -C//2\n",
    "print(A)\n",
    "print(np.sign(A[-1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
