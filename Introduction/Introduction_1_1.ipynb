{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Polynomial Curve Fitting\n",
    "\n",
    "## This is a simple regression problem.\n",
    "\n",
    "**Original function**: $t = sin(2\\pi x)+b,\\qquad b = noise\\ from\\ Gaussian\\ distribution$   \n",
    "**Training data**: input $\\mathbf{x}\\equiv\\{x_1,\\cdots,x_{N}\\}^T$, output $\\mathbf{t}\\equiv\\{t_1,\\cdots,t_{N}\\}, N=10,\\mathbf{x}\\in [0,1]$\n",
    "\n",
    "Our model:\n",
    "$\\displaystyle{y(x,\\mathbf{w})=w_0+w_1x+w_2x^2+\\cdots+w_Mx^M=\\sum_{j=0}^Mw_jx^j}$  \n",
    "$M$:order of the polynomial.  \n",
    "$x^j$:denotes $x$ raised to the power of $j$.  \n",
    "$w_j$:coefficients of the polynomial, collectively denoted by the vector $\\mathbf{w}$.\n",
    "\n",
    "This polynomial is a nonlinear function of $x$, but a linear function of the unknown coefficients $\\mathbf{w}$. Thus it's a linear model. \n",
    "\n",
    "\n",
    "Error function, use to measure the misfit between $y(x,\\mathbf{w})$, for any given value of $\\mathbf{w}$, and the training set data points.    \n",
    "$\\displaystyle{E(\\mathbf{w})=\\frac{1}{2}\\sum_{n=1}^N\\{y(x_n,\\mathbf{w})-t_n\\}^2}$\n",
    "\n",
    "It's a quadratic function of the coefficients $\\mathbf{w}$, so we can easily find out the best coefficients on where the partial derivates of the function is zero. In this case, we get the minimun error from the function.\n",
    "\n",
    "\n",
    "## How we choose the order M of the polynomial.\n",
    "- M=0, a horizontal line, poor fits.\n",
    "- M=1, a line, poor fits.\n",
    "- M=3, a third-order polynomial, best fits to $sin(2\\pi x)$.\n",
    "- M=9, a nineth-order polynomial, excellent fits to training data, but poor fits to $sin(2\\pi x)$\n",
    "\n",
    "Let the best coefficients of these N-order functions to be $\\mathbf{w}^\\star$. Use the best functions $y(x, \\mathbf{w}^\\star)$ from these orders and test them with the test data. We find that the root-mean-square error decrease from $M=0$ to $M=3$, then burst on $M=9$.Why??  \n",
    "Decreasing from $M=0$ to $M=3$ is quite straightforward. For higher order like $M=9$ polynomial, the coefficients have become finely tuned to the training data by developing large positive and negative values so that the corresponding polynomial function matches each of the data point exactly, but between data points the function exhibits the large oscillations.Intuitively, what is happening is that the more flexible polynomials with large values of M are becoming increasingly tuned to the random noise on the target values, which is called **over-fitting**.\n",
    "\n",
    "\n",
    "## Improve the over-fitting problem.\n",
    "- Increase the training set.The larger the data set, the more complex the model that we can afford to fit to the data.\n",
    "- The number of parameters in a model should also be limited base on the size of training set, we can use Bayesian approach to avoid over-fitting (later chapters).\n",
    "- Regularization. Add a penalty term to the error function in order to discourage the coefficients from reaching large values.  \n",
    "$\\displaystyle{\\tilde{E}(\\mathbf{w})=\\frac{1}{2}\\sum_{n=1}^N\\{y(x_n, \\mathbf{w})-t_n\\}^2+\\frac{\\lambda}{2}\\left\\|\\mathbf{w}\\right\\|^2}$  \n",
    "where $\\left\\|\\mathbf{w}\\right\\|^2\\equiv\\mathbf{w}\\mathbf{w}^T=w_1^2+\\cdots+w+M^2$.\n",
    "\n",
    "There is a simple way for achieving best model (function), we are suggested to take the available data and partitioning it into a training set , used to determine the coefficients $\\mathbf{w}$, and a separate validation set, used to optimize the model complexity (either $M$ or $\\lambda$). In many cases ,however, this will prove to be too wasteful of valuable training data, and we have to seek more sophisticated approaches."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
