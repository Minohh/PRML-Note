{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequentist\n",
    "\n",
    "# Bayesian\n",
    "\n",
    "# Bayes' theorem\n",
    "$$p(\\mathbf{w}|\\mathcal{D})=\\frac{p(\\mathcal{D}|\\mathbf{w})p(\\mathbf{w})}{p(\\mathcal{D})}$$\n",
    "Prior probability $p(\\mathbf{w})$.  \n",
    "Condictional probability $p(\\mathcal{D}|\\mathbf{w})$.  \n",
    "If $p(\\mathcal{D}|\\mathbf{w})$ is the quantity evaluated for the observed data set $\\mathcal{D}$, it is called likelihood fuction which expresses how probable the observed data set is fro different settings of the parameter vector $\\mathbf{w}$. In this case, it's not a probability distribution because its integration is not equal to 1.     \n",
    "Posterior probability $p(\\mathbf{w}|\\mathcal{D})$.  \n",
    "\n",
    "Given the difinition of likelihood, we can state Bayes' theorem in words  \n",
    "$$posterior \\propto likelihood \\times prior$$\n",
    "where all of these quantities are viewed as functions of $\\mathbf{w}$. The denominator in Bayes' theorem is the normalization constant, which ensures that the posterior ditribution on the left-hand side is a valid probability density and integrates to one.\n",
    "$$p(\\mathcal{D})=\\int p(\\mathcal{D}|\\mathbf{w})p(\\mathbf{w})d\\mathbf{w}$$\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
